{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jt5iII9UVB05","outputId":"a4a36d30-99c2-4438-86eb-28a5f1f96484"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'dataset': 'one_month_network_202010', 'epochs': 1000, 'hidden': 16, 'bases': -1, 'learnrate': 0.001, 'l2norm': 0.0005, 'text_model': 'HLSTM', 'supervise_flag': 'supervise', 'pred_type': 'all'}\n","898999 112376 112374\n","y:1123749\n","num_nodes:1435367\n","support:1\n","2\n","Data loaded successfully!\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\r15938it [00:00, 159366.09it/s]\r35511it [00:00, 180744.55it/s]\r54619it [00:00, 185455.89it/s]\r73183it [00:00, 185523.58it/s]\r91829it [00:00, 185851.56it/s]\r110793it [00:00, 187135.35it/s]\r130125it [00:00, 189135.82it/s]\r150966it [00:00, 195263.87it/s]\r171016it [00:00, 196882.60it/s]\r190705it [00:01, 191988.70it/s]\r210832it [00:01, 194775.32it/s]\r230333it [00:01, 75484.36it/s] \r249889it [00:01, 92200.53it/s]\r269995it [00:01, 110553.59it/s]\r288964it [00:02, 125912.35it/s]\r307877it [00:02, 139631.55it/s]\r326434it [00:02, 150503.54it/s]\r345485it [00:02, 160610.61it/s]\r363947it [00:02, 163859.45it/s]\r382168it [00:02, 168830.55it/s]\r401763it [00:02, 176395.18it/s]\r423567it [00:02, 188260.95it/s]\r443493it [00:02, 191438.57it/s]\r463148it [00:02, 190997.46it/s]\r482622it [00:03, 192088.59it/s]\r502084it [00:03, 191340.81it/s]\r521396it [00:03, 188350.44it/s]\r540363it [00:03, 187538.65it/s]\r559208it [00:03, 184932.89it/s]\r577769it [00:03, 184905.63it/s]\r596307it [00:03, 182088.40it/s]\r614554it [00:04, 49439.12it/s] \r632190it [00:04, 62366.16it/s]\r649896it [00:04, 76934.40it/s]\r667957it [00:04, 92851.88it/s]\r685524it [00:05, 107750.89it/s]\r702198it [00:05, 112548.69it/s]\r720387it [00:05, 127476.90it/s]\r738556it [00:05, 140226.03it/s]\r757194it [00:05, 151831.46it/s]\r776510it [00:05, 162753.30it/s]\r795442it [00:05, 170032.06it/s]\r813736it [00:05, 173657.83it/s]\r832409it [00:05, 177402.49it/s]\r850827it [00:06, 179368.04it/s]\r869325it [00:06, 181009.20it/s]\r887891it [00:06, 182378.51it/s]\r906578it [00:06, 183282.39it/s]\r925068it [00:06, 183643.33it/s]\r944030it [00:06, 185420.60it/s]\r962689it [00:06, 185765.50it/s]\r981323it [00:06, 183406.59it/s]\r999710it [00:06, 182851.01it/s]\r1018028it [00:06, 180466.73it/s]\r1036627it [00:07, 182075.96it/s]\r1054857it [00:07, 181371.88it/s]\r1073522it [00:07, 182933.49it/s]\r1091828it [00:07, 179418.56it/s]\r1109792it [00:08, 33437.63it/s] \r1123750it [00:08, 124866.42it/s]\n","\r  0%|          | 0/1193517 [00:00<?, ?it/s]\r  0%|          | 1588/1193517 [00:00<01:15, 15874.04it/s]\r  0%|          | 3263/1193517 [00:00<01:12, 16385.91it/s]\r  0%|          | 4929/1193517 [00:00<01:12, 16507.96it/s]\r  1%|          | 6601/1193517 [00:00<01:11, 16591.02it/s]\r  1%|          | 8274/1193517 [00:00<01:11, 16640.82it/s]\r  1%|          | 9954/1193517 [00:00<01:10, 16692.43it/s]\r  1%|          | 11629/1193517 [00:00<01:10, 16707.95it/s]\r  1%|          | 13317/1193517 [00:00<01:10, 16760.80it/s]\r  1%|▏         | 15008/1193517 [00:00<01:10, 16805.56it/s]\r  1%|▏         | 16692/1193517 [00:01<01:09, 16813.47it/s]\r  2%|▏         | 18374/1193517 [00:01<01:10, 16714.97it/s]\r  2%|▏         | 20072/1193517 [00:01<01:09, 16793.23it/s]\r  2%|▏         | 21752/1193517 [00:01<01:09, 16787.55it/s]\r  2%|▏         | 23431/1193517 [00:01<01:09, 16722.55it/s]\r  2%|▏         | 25118/1193517 [00:01<01:09, 16763.76it/s]\r  2%|▏         | 26801/1193517 [00:01<01:09, 16782.54it/s]\r  2%|▏         | 28483/1193517 [00:01<01:09, 16791.58it/s]\r  3%|▎         | 30167/1193517 [00:01<01:09, 16803.66it/s]\r  3%|▎         | 31848/1193517 [00:01<01:09, 16780.94it/s]\r  3%|▎         | 33527/1193517 [00:02<01:09, 16776.06it/s]\r  3%|▎         | 35205/1193517 [00:02<01:09, 16666.61it/s]\r  3%|▎         | 36872/1193517 [00:02<01:09, 16659.75it/s]\r  3%|▎         | 38552/1193517 [00:02<01:09, 16700.42it/s]\r  3%|▎         | 40248/1193517 [00:02<01:08, 16775.48it/s]\r  4%|▎         | 41928/1193517 [00:02<01:08, 16780.89it/s]\r  4%|▎         | 43613/1193517 [00:02<01:08, 16800.17it/s]\r  4%|▍         | 45294/1193517 [00:02<01:08, 16738.89it/s]\r  4%|▍         | 46968/1193517 [00:02<01:08, 16727.92it/s]\r  4%|▍         | 48641/1193517 [00:02<01:08, 16723.90it/s]\r  4%|▍         | 50317/1193517 [00:03<01:08, 16732.51it/s]\r  4%|▍         | 51993/1193517 [00:03<01:08, 16738.68it/s]\r  4%|▍         | 53667/1193517 [00:03<01:08, 16612.93it/s]\r  5%|▍         | 55336/1193517 [00:03<01:08, 16634.50it/s]\r  5%|▍         | 57015/1193517 [00:03<01:08, 16679.27it/s]\r  5%|▍         | 58695/1193517 [00:03<01:07, 16715.00it/s]\r  5%|▌         | 60367/1193517 [00:04<02:38, 7143.94it/s] \r  5%|▌         | 62026/1193517 [00:04<02:11, 8603.17it/s]\r  5%|▌         | 63636/1193517 [00:04<01:53, 9957.63it/s]\r  5%|▌         | 65280/1193517 [00:04<01:39, 11287.26it/s]\r  6%|▌         | 66948/1193517 [00:04<01:30, 12508.41it/s]\r  6%|▌         | 68608/1193517 [00:04<01:23, 13508.35it/s]\r  6%|▌         | 70280/1193517 [00:04<01:18, 14338.48it/s]\r  6%|▌         | 71964/1193517 [00:04<01:14, 15012.19it/s]\r  6%|▌         | 73646/1193517 [00:04<01:12, 15512.69it/s]\r  6%|▋         | 75306/1193517 [00:04<01:10, 15819.89it/s]\r  6%|▋         | 76965/1193517 [00:05<01:09, 16041.75it/s]\r  7%|▋         | 78619/1193517 [00:05<01:11, 15662.31it/s]\r  7%|▋         | 80281/1193517 [00:05<01:09, 15935.13it/s]\r  7%|▋         | 81942/1193517 [00:05<01:08, 16130.35it/s]\r  7%|▋         | 83621/1193517 [00:05<01:08, 16321.23it/s]\r  7%|▋         | 85286/1193517 [00:05<01:07, 16415.55it/s]\r  7%|▋         | 86953/1193517 [00:05<01:07, 16488.92it/s]\r  7%|▋         | 88609/1193517 [00:05<01:07, 16261.18it/s]\r  8%|▊         | 90241/1193517 [00:05<01:07, 16248.42it/s]\r  8%|▊         | 91906/1193517 [00:05<01:07, 16367.05it/s]\r  8%|▊         | 93569/1193517 [00:06<01:06, 16443.48it/s]\r  8%|▊         | 95232/1193517 [00:06<01:06, 16498.84it/s]\r  8%|▊         | 96884/1193517 [00:06<01:06, 16501.61it/s]\r  8%|▊         | 98540/1193517 [00:06<01:06, 16518.29it/s]\r  8%|▊         | 100202/1193517 [00:06<01:06, 16546.32it/s]\r  9%|▊         | 101874/1193517 [00:06<01:05, 16595.99it/s]\r  9%|▊         | 103534/1193517 [00:06<01:05, 16560.88it/s]\r  9%|▉         | 105213/1193517 [00:06<01:05, 16628.68it/s]\r  9%|▉         | 106903/1193517 [00:06<01:05, 16706.68it/s]\r  9%|▉         | 108580/1193517 [00:06<01:04, 16722.43it/s]\r  9%|▉         | 110268/1193517 [00:07<01:04, 16767.93it/s]\r  9%|▉         | 111959/1193517 [00:07<01:04, 16807.85it/s]\r 10%|▉         | 113647/1193517 [00:07<01:04, 16827.38it/s]\r 10%|▉         | 115339/1193517 [00:07<01:03, 16852.23it/s]\r 10%|▉         | 117025/1193517 [00:07<01:04, 16722.98it/s]\r 10%|▉         | 118698/1193517 [00:07<01:04, 16697.60it/s]\r 10%|█         | 120368/1193517 [00:07<01:04, 16633.54it/s]\r 10%|█         | 122045/1193517 [00:07<01:04, 16671.78it/s]\r 10%|█         | 123727/1193517 [00:07<01:03, 16715.72it/s]\r 11%|█         | 125399/1193517 [00:07<01:03, 16697.53it/s]\r 11%|█         | 127074/1193517 [00:08<01:03, 16712.13it/s]\r 11%|█         | 128764/1193517 [00:08<01:03, 16766.88it/s]\r 11%|█         | 130441/1193517 [00:08<01:03, 16749.40it/s]\r 11%|█         | 132121/1193517 [00:08<01:03, 16763.13it/s]\r 11%|█         | 133798/1193517 [00:08<01:03, 16752.93it/s]\r 11%|█▏        | 135475/1193517 [00:08<01:03, 16756.08it/s]\r 11%|█▏        | 137151/1193517 [00:08<01:03, 16743.37it/s]\r 12%|█▏        | 138826/1193517 [00:08<01:02, 16743.69it/s]\r 12%|█▏        | 140510/1193517 [00:08<01:02, 16771.49it/s]\r 12%|█▏        | 142188/1193517 [00:08<01:02, 16724.60it/s]\r 12%|█▏        | 143861/1193517 [00:09<01:04, 16377.05it/s]\r 12%|█▏        | 145529/1193517 [00:09<01:03, 16465.89it/s]\r 12%|█▏        | 147206/1193517 [00:09<01:03, 16553.54it/s]\r 12%|█▏        | 148877/1193517 [00:09<01:02, 16599.69it/s]\r 13%|█▎        | 150560/1193517 [00:09<01:02, 16665.80it/s]\r 13%|█▎        | 152255/1193517 [00:09<01:02, 16748.15it/s]\r 13%|█▎        | 153946/1193517 [00:09<01:01, 16793.88it/s]\r 13%|█▎        | 155626/1193517 [00:09<01:01, 16745.28it/s]\r 13%|█▎        | 157301/1193517 [00:09<01:02, 16558.69it/s]\r 13%|█▎        | 158958/1193517 [00:09<01:02, 16561.48it/s]\r 13%|█▎        | 160637/1193517 [00:10<01:02, 16627.58it/s]\r 14%|█▎        | 162311/1193517 [00:10<01:01, 16658.60it/s]\r 14%|█▎        | 163978/1193517 [00:10<01:01, 16630.63it/s]\r 14%|█▍        | 165642/1193517 [00:10<01:01, 16587.44it/s]\r 14%|█▍        | 167301/1193517 [00:10<01:01, 16569.82it/s]\r 14%|█▍        | 168967/1193517 [00:10<01:01, 16595.21it/s]\r 14%|█▍        | 170627/1193517 [00:10<01:01, 16574.05it/s]\r 14%|█▍        | 172292/1193517 [00:10<01:01, 16594.31it/s]\r 15%|█▍        | 173952/1193517 [00:10<01:02, 16344.73it/s]\r 15%|█▍        | 175588/1193517 [00:11<01:03, 15946.83it/s]\r 15%|█▍        | 177257/1193517 [00:11<01:02, 16161.75it/s]\r 15%|█▍        | 178924/1193517 [00:11<01:02, 16311.13it/s]\r 15%|█▌        | 180557/1193517 [00:11<01:02, 16252.65it/s]\r 15%|█▌        | 182184/1193517 [00:11<01:02, 16176.88it/s]\r 15%|█▌        | 183803/1193517 [00:11<01:02, 16049.16it/s]\r 16%|█▌        | 185409/1193517 [00:11<01:02, 16020.41it/s]\r 16%|█▌        | 187025/1193517 [00:11<01:02, 16060.12it/s]\r 16%|█▌        | 188683/1193517 [00:11<01:01, 16213.16it/s]\r 16%|█▌        | 190338/1193517 [00:11<01:01, 16311.60it/s]\r 16%|█▌        | 191978/1193517 [00:12<01:01, 16335.19it/s]\r 16%|█▌        | 193618/1193517 [00:12<01:01, 16351.99it/s]\r 16%|█▋        | 195259/1193517 [00:12<01:00, 16367.88it/s]\r 16%|█▋        | 196905/1193517 [00:12<01:00, 16392.96it/s]\r 17%|█▋        | 198558/1193517 [00:12<01:00, 16432.92it/s]\r 17%|█▋        | 200202/1193517 [00:12<01:01, 16255.79it/s]\r 17%|█▋        | 201849/1193517 [00:12<01:00, 16319.20it/s]\r 17%|█▋        | 203482/1193517 [00:12<01:00, 16321.89it/s]\r 17%|█▋        | 205133/1193517 [00:12<01:00, 16376.58it/s]\r 17%|█▋        | 206771/1193517 [00:12<01:00, 16276.00it/s]\r 17%|█▋        | 208399/1193517 [00:13<01:01, 16143.96it/s]\r 18%|█▊        | 210036/1193517 [00:13<01:00, 16209.71it/s]\r 18%|█▊        | 211716/1193517 [00:13<00:59, 16383.35it/s]\r 18%|█▊        | 213417/1193517 [00:13<00:59, 16568.29it/s]\r 18%|█▊        | 215088/1193517 [00:13<00:58, 16608.21it/s]\r 18%|█▊        | 216774/1193517 [00:13<00:58, 16683.04it/s]\r 18%|█▊        | 218474/1193517 [00:13<00:58, 16775.23it/s]\r 18%|█▊        | 220155/1193517 [00:13<00:57, 16783.73it/s]\r 19%|█▊        | 221834/1193517 [00:13<00:57, 16766.13it/s]\r 19%|█▊        | 223511/1193517 [00:13<00:58, 16671.14it/s]\r 19%|█▉        | 225179/1193517 [00:14<00:58, 16602.16it/s]\r 19%|█▉        | 226840/1193517 [00:14<00:58, 16445.52it/s]\r 19%|█▉        | 228485/1193517 [00:14<00:59, 16196.22it/s]\r 19%|█▉        | 230106/1193517 [00:14<00:59, 16173.20it/s]\r 19%|█▉        | 231724/1193517 [00:14<01:01, 15719.91it/s]\r 20%|█▉        | 233303/1193517 [00:14<01:01, 15738.25it/s]\r 20%|█▉        | 234889/1193517 [00:14<01:00, 15773.32it/s]\r 20%|█▉        | 236532/1193517 [00:14<00:59, 15965.63it/s]\r 20%|█▉        | 238137/1193517 [00:14<00:59, 15988.49it/s]\r 20%|██        | 239737/1193517 [00:14<01:01, 15469.23it/s]\r 20%|██        | 241371/1193517 [00:15<01:00, 15721.37it/s]\r 20%|██        | 243010/1193517 [00:15<00:59, 15916.50it/s]\r 20%|██        | 244605/1193517 [00:15<01:01, 15502.28it/s]\r 21%|██        | 246191/1193517 [00:15<01:00, 15605.48it/s]\r 21%|██        | 247757/1193517 [00:15<01:00, 15618.63it/s]\r 21%|██        | 249329/1193517 [00:15<01:00, 15647.46it/s]\r 21%|██        | 250910/1193517 [00:15<01:00, 15693.90it/s]\r 21%|██        | 252523/1193517 [00:15<00:59, 15823.44it/s]\r 21%|██▏       | 254107/1193517 [00:15<00:59, 15742.32it/s]\r 21%|██▏       | 255682/1193517 [00:15<01:01, 15184.25it/s]\r 22%|██▏       | 257235/1193517 [00:16<01:01, 15282.64it/s]\r 22%|██▏       | 258790/1193517 [00:16<01:00, 15358.28it/s]\r 22%|██▏       | 260393/1193517 [00:16<00:59, 15555.09it/s]\r 22%|██▏       | 262003/1193517 [00:16<00:59, 15714.69it/s]\r 22%|██▏       | 263597/1193517 [00:16<00:58, 15779.70it/s]\r 22%|██▏       | 265213/1193517 [00:16<00:58, 15892.30it/s]\r 22%|██▏       | 266844/1193517 [00:16<00:57, 16016.21it/s]\r 22%|██▏       | 268487/1193517 [00:16<00:57, 16137.33it/s]\r 23%|██▎       | 270106/1193517 [00:16<00:57, 16150.89it/s]\r 23%|██▎       | 271722/1193517 [00:16<00:57, 16130.88it/s]\r 23%|██▎       | 273336/1193517 [00:17<00:57, 16107.23it/s]\r 23%|██▎       | 274953/1193517 [00:17<00:56, 16125.42it/s]\r 23%|██▎       | 276566/1193517 [00:17<00:57, 15973.85it/s]\r 23%|██▎       | 278164/1193517 [00:17<00:57, 15795.59it/s]\r 23%|██▎       | 279745/1193517 [00:17<00:58, 15550.62it/s]\r 24%|██▎       | 281324/1193517 [00:17<00:58, 15619.47it/s]\r 24%|██▎       | 282889/1193517 [00:17<00:58, 15627.93it/s]\r 24%|██▍       | 284453/1193517 [00:17<01:00, 15052.62it/s]\r 24%|██▍       | 286069/1193517 [00:17<00:59, 15372.64it/s]\r 24%|██▍       | 287683/1193517 [00:18<00:58, 15594.88it/s]\r 24%|██▍       | 289299/1193517 [00:18<00:57, 15760.02it/s]\r 24%|██▍       | 290878/1193517 [00:18<00:58, 15413.13it/s]\r 25%|██▍       | 292483/1193517 [00:18<00:57, 15597.27it/s]\r 25%|██▍       | 294096/1193517 [00:18<00:57, 15753.74it/s]\r 25%|██▍       | 295700/1193517 [00:18<00:56, 15838.24it/s]\r 25%|██▍       | 297287/1193517 [00:18<00:56, 15846.31it/s]\r 25%|██▌       | 298906/1193517 [00:18<00:56, 15947.55it/s]\r 25%|██▌       | 300524/1193517 [00:18<00:55, 16014.54it/s]\r 25%|██▌       | 302161/1193517 [00:18<00:55, 16118.50it/s]\r 25%|██▌       | 303803/1193517 [00:19<00:54, 16206.50it/s]\r 26%|██▌       | 305424/1193517 [00:19<00:55, 16021.76it/s]\r 26%|██▌       | 307027/1193517 [00:19<00:55, 16004.86it/s]\r 26%|██▌       | 308628/1193517 [00:19<00:55, 16005.68it/s]\r 26%|██▌       | 310242/1193517 [00:19<00:55, 16045.11it/s]\r 26%|██▌       | 311888/1193517 [00:19<00:54, 16167.10it/s]\r 26%|██▋       | 313516/1193517 [00:19<00:54, 16200.20it/s]\r 26%|██▋       | 315151/1193517 [00:19<00:54, 16244.31it/s]\r 27%|██▋       | 316776/1193517 [00:19<00:54, 16181.37it/s]\r 27%|██▋       | 318396/1193517 [00:19<00:54, 16183.95it/s]\r 27%|██▋       | 320015/1193517 [00:20<00:55, 15601.69it/s]\r 27%|██▋       | 321615/1193517 [00:20<00:55, 15715.13it/s]\r 27%|██▋       | 323221/1193517 [00:20<00:55, 15814.98it/s]\r 27%|██▋       | 324806/1193517 [00:20<00:55, 15724.49it/s]\r 27%|██▋       | 326399/1193517 [00:20<00:54, 15781.76it/s]\r 27%|██▋       | 327979/1193517 [00:20<00:54, 15761.21it/s]\r 28%|██▊       | 329619/1193517 [00:20<00:54, 15948.39it/s]\r 28%|██▊       | 331215/1193517 [00:20<00:54, 15849.01it/s]\r 28%|██▊       | 332831/1193517 [00:20<00:53, 15940.82it/s]\r 28%|██▊       | 334449/1193517 [00:20<00:53, 16011.48it/s]\r 28%|██▊       | 336070/1193517 [00:21<00:53, 16068.25it/s]\r 28%|██▊       | 337681/1193517 [00:21<00:53, 16079.85it/s]\r 28%|██▊       | 339304/1193517 [00:21<00:52, 16123.95it/s]\r 29%|██▊       | 340917/1193517 [00:21<00:53, 16025.67it/s]\r 29%|██▊       | 342520/1193517 [00:21<00:53, 15990.91it/s]\r 29%|██▉       | 344155/1193517 [00:21<00:52, 16096.44it/s]\r 29%|██▉       | 345779/1193517 [00:21<00:52, 16138.08it/s]\r 29%|██▉       | 347393/1193517 [00:21<00:52, 16049.94it/s]\r 29%|██▉       | 348999/1193517 [00:21<00:54, 15513.73it/s]\r 29%|██▉       | 350555/1193517 [00:21<00:57, 14573.62it/s]\r 30%|██▉       | 352103/1193517 [00:22<00:56, 14827.75it/s]\r 30%|██▉       | 353700/1193517 [00:22<00:55, 15153.34it/s]\r 30%|██▉       | 355292/1193517 [00:22<00:54, 15375.22it/s]\r 30%|██▉       | 356837/1193517 [00:22<00:54, 15348.98it/s]\r 30%|███       | 358400/1193517 [00:22<00:54, 15431.49it/s]\r 30%|███       | 359968/1193517 [00:22<00:53, 15504.46it/s]\r 30%|███       | 361521/1193517 [00:22<00:53, 15437.77it/s]\r 30%|███       | 363087/1193517 [00:22<00:53, 15500.70it/s]\r 31%|███       | 364639/1193517 [00:22<00:53, 15466.37it/s]\r 31%|███       | 366211/1193517 [00:22<00:53, 15540.33it/s]\r 31%|███       | 367766/1193517 [00:23<00:53, 15488.63it/s]\r 31%|███       | 369316/1193517 [00:23<00:53, 15440.31it/s]\r 31%|███       | 370862/1193517 [00:23<00:53, 15444.93it/s]\r 31%|███       | 372407/1193517 [00:23<00:53, 15407.24it/s]\r 31%|███▏      | 373948/1193517 [00:23<00:54, 14912.07it/s]\r 31%|███▏      | 375468/1193517 [00:23<00:54, 14995.00it/s]\r 32%|███▏      | 376971/1193517 [00:23<00:56, 14503.53it/s]\r 32%|███▏      | 378519/1193517 [00:23<00:55, 14785.49it/s]\r 32%|███▏      | 380073/1193517 [00:23<00:54, 15004.01it/s]\r 32%|███▏      | 381587/1193517 [00:24<00:53, 15041.85it/s]\r 32%|███▏      | 383150/1193517 [00:24<00:53, 15215.47it/s]\r 32%|███▏      | 384722/1193517 [00:24<00:52, 15362.75it/s]\r 32%|███▏      | 386260/1193517 [00:24<00:53, 15058.90it/s]\r 32%|███▏      | 387824/1193517 [00:24<00:52, 15228.33it/s]\r 33%|███▎      | 389388/1193517 [00:24<00:52, 15349.29it/s]\r 33%|███▎      | 390941/1193517 [00:24<00:52, 15402.49it/s]\r 33%|███▎      | 392483/1193517 [00:24<00:52, 15348.92it/s]\r 33%|███▎      | 394019/1193517 [00:24<00:52, 15340.63it/s]\r 33%|███▎      | 395574/1193517 [00:24<00:51, 15401.95it/s]\r 33%|███▎      | 397147/1193517 [00:25<00:51, 15498.34it/s]\r 33%|███▎      | 398730/1193517 [00:25<00:50, 15595.41it/s]\r 34%|███▎      | 400311/1193517 [00:25<00:50, 15656.86it/s]\r 34%|███▎      | 401877/1193517 [00:25<00:50, 15649.89it/s]\r 34%|███▍      | 403447/1193517 [00:25<00:50, 15663.80it/s]\r 34%|███▍      | 405014/1193517 [00:25<00:50, 15550.15it/s]\r 34%|███▍      | 406570/1193517 [00:25<00:50, 15464.01it/s]\r 34%|███▍      | 408117/1193517 [00:25<00:51, 15278.69it/s]\r 34%|███▍      | 409680/1193517 [00:25<00:50, 15379.68it/s]\r 34%|███▍      | 411219/1193517 [00:25<00:50, 15367.00it/s]\r 35%|███▍      | 412757/1193517 [00:26<00:54, 14392.63it/s]\r 35%|███▍      | 414279/1193517 [00:26<00:53, 14627.92it/s]\r 35%|███▍      | 415794/1193517 [00:26<00:52, 14777.65it/s]\r 35%|███▍      | 417280/1193517 [00:26<00:53, 14470.21it/s]\r 35%|███▌      | 418812/1193517 [00:26<00:52, 14713.97it/s]\r 35%|███▌      | 420335/1193517 [00:26<00:52, 14863.71it/s]\r 35%|███▌      | 421929/1193517 [00:26<00:50, 15178.49it/s]\r 35%|███▌      | 423473/1193517 [00:26<00:50, 15252.99it/s]\r 36%|███▌      | 425068/1193517 [00:26<00:49, 15459.21it/s]\r 36%|███▌      | 426616/1193517 [00:26<00:50, 15074.02it/s]\r 36%|███▌      | 428214/1193517 [00:27<00:49, 15338.27it/s]\r 36%|███▌      | 429797/1193517 [00:27<00:49, 15482.12it/s]\r 36%|███▌      | 431350/1193517 [00:27<00:49, 15494.37it/s]\r 36%|███▋      | 432902/1193517 [00:27<00:49, 15316.82it/s]\r 36%|███▋      | 434436/1193517 [00:27<00:49, 15321.45it/s]\r 37%|███▋      | 435970/1193517 [00:27<00:49, 15173.62it/s]\r 37%|███▋      | 437498/1193517 [00:27<00:49, 15202.60it/s]\r 37%|███▋      | 439063/1193517 [00:27<00:49, 15334.40it/s]\r 37%|███▋      | 440598/1193517 [00:27<00:50, 14923.78it/s]\r 37%|███▋      | 442163/1193517 [00:27<00:49, 15134.63it/s]\r 37%|███▋      | 443768/1193517 [00:28<00:48, 15403.88it/s]\r 37%|███▋      | 445370/1193517 [00:28<00:48, 15583.90it/s]\r 37%|███▋      | 446979/1193517 [00:28<00:47, 15732.51it/s]\r 38%|███▊      | 448554/1193517 [00:28<00:47, 15737.33it/s]\r 38%|███▊      | 450145/1193517 [00:28<00:47, 15787.24it/s]\r 38%|███▊      | 451731/1193517 [00:28<00:46, 15806.39it/s]\r 38%|███▊      | 453313/1193517 [00:28<00:46, 15802.97it/s]\r 38%|███▊      | 454922/1193517 [00:28<00:46, 15886.05it/s]\r 38%|███▊      | 456511/1193517 [00:28<00:46, 15828.79it/s]\r 38%|███▊      | 458095/1193517 [00:28<00:46, 15682.81it/s]\r 39%|███▊      | 459664/1193517 [00:29<00:46, 15634.01it/s]\r 39%|███▊      | 461244/1193517 [00:29<00:46, 15680.75it/s]\r 39%|███▉      | 462867/1193517 [00:29<00:46, 15842.04it/s]\r 39%|███▉      | 464452/1193517 [00:29<00:47, 15393.08it/s]\r 39%|███▉      | 466017/1193517 [00:29<00:47, 15467.35it/s]\r 39%|███▉      | 467609/1193517 [00:29<00:46, 15600.13it/s]\r 39%|███▉      | 469187/1193517 [00:29<00:46, 15650.55it/s]\r 39%|███▉      | 470783/1193517 [00:29<00:45, 15741.99it/s]\r 40%|███▉      | 472359/1193517 [00:29<00:46, 15389.60it/s]\r 40%|███▉      | 473962/1193517 [00:30<00:46, 15576.27it/s]\r 40%|███▉      | 475587/1193517 [00:30<00:45, 15772.53it/s]\r 40%|███▉      | 477166/1193517 [00:30<00:46, 15301.19it/s]\r 40%|████      | 478741/1193517 [00:30<00:46, 15430.42it/s]\r 40%|████      | 480332/1193517 [00:30<00:45, 15569.43it/s]\r 40%|████      | 481920/1193517 [00:30<00:45, 15660.71it/s]\r 41%|████      | 483488/1193517 [00:30<00:45, 15462.31it/s]\r 41%|████      | 485036/1193517 [00:30<00:45, 15452.28it/s]\r 41%|████      | 486674/1193517 [00:30<00:44, 15725.45it/s]\r 41%|████      | 488331/1193517 [00:30<00:44, 15973.73it/s]\r 41%|████      | 489965/1193517 [00:31<00:43, 16081.84it/s]\r 41%|████      | 491598/1193517 [00:31<00:43, 16153.78it/s]\r 41%|████▏     | 493214/1193517 [00:31<00:44, 15634.34it/s]\r 41%|████▏     | 494840/1193517 [00:31<00:44, 15816.36it/s]\r 42%|████▏     | 496458/1193517 [00:31<00:43, 15921.88it/s]\r 42%|████▏     | 498053/1193517 [00:31<00:44, 15643.98it/s]\r 42%|████▏     | 499691/1193517 [00:31<00:43, 15858.62it/s]\r 42%|████▏     | 501309/1193517 [00:31<00:43, 15952.24it/s]\r 42%|████▏     | 502906/1193517 [00:31<00:43, 15923.43it/s]\r 42%|████▏     | 504527/1193517 [00:31<00:43, 16006.81it/s]\r 42%|████▏     | 506129/1193517 [00:32<00:43, 15964.04it/s]\r 43%|████▎     | 507727/1193517 [00:32<00:43, 15769.02it/s]\r 43%|████▎     | 509305/1193517 [00:32<00:44, 15389.80it/s]\r 43%|████▎     | 510884/1193517 [00:32<00:44, 15505.27it/s]\r 43%|████▎     | 512494/1193517 [00:32<00:43, 15679.70it/s]\r 43%|████▎     | 514127/1193517 [00:32<00:42, 15869.48it/s]\r 43%|████▎     | 515716/1193517 [00:32<00:42, 15803.06it/s]\r 43%|████▎     | 517363/1193517 [00:32<00:42, 15998.57it/s]\r 43%|████▎     | 519003/1193517 [00:32<00:41, 16117.17it/s]\r 44%|████▎     | 520652/1193517 [00:32<00:41, 16227.96it/s]\r 44%|████▍     | 522318/1193517 [00:33<00:41, 16353.83it/s]\r 44%|████▍     | 523971/1193517 [00:33<00:40, 16405.78it/s]\r 44%|████▍     | 525612/1193517 [00:33<00:41, 16245.00it/s]\r 44%|████▍     | 527238/1193517 [00:33<00:41, 16144.93it/s]\r 44%|████▍     | 528886/1193517 [00:33<00:40, 16241.40it/s]\r 44%|████▍     | 530542/1193517 [00:33<00:40, 16334.38it/s]\r 45%|████▍     | 532198/1193517 [00:33<00:40, 16399.85it/s]\r 45%|████▍     | 533839/1193517 [00:33<00:40, 16252.84it/s]\r 45%|████▍     | 535505/1193517 [00:33<00:40, 16371.06it/s]\r 45%|████▌     | 537143/1193517 [00:33<00:40, 16335.38it/s]\r 45%|████▌     | 538788/1193517 [00:34<00:40, 16367.39it/s]\r 45%|████▌     | 540447/1193517 [00:34<00:39, 16432.00it/s]\r 45%|████▌     | 542127/1193517 [00:34<00:39, 16538.45it/s]\r 46%|████▌     | 543782/1193517 [00:34<00:39, 16361.23it/s]\r 46%|████▌     | 545448/1193517 [00:34<00:39, 16447.08it/s]\r 46%|████▌     | 547118/1193517 [00:34<00:39, 16520.08it/s]\r 46%|████▌     | 548771/1193517 [00:34<00:39, 16460.43it/s]\r 46%|████▌     | 550455/1193517 [00:34<00:38, 16571.99it/s]\r 46%|████▋     | 552113/1193517 [00:34<00:39, 16386.19it/s]\r 46%|████▋     | 553773/1193517 [00:34<00:38, 16449.33it/s]\r 47%|████▋     | 555424/1193517 [00:35<00:38, 16465.29it/s]\r 47%|████▋     | 557155/1193517 [00:35<00:38, 16715.24it/s]\r 47%|████▋     | 558846/1193517 [00:35<00:37, 16770.89it/s]\r 47%|████▋     | 560525/1193517 [00:35<00:37, 16775.33it/s]\r 47%|████▋     | 562203/1193517 [00:35<00:38, 16535.44it/s]\r 47%|████▋     | 563858/1193517 [00:35<00:38, 16412.44it/s]\r 47%|████▋     | 565576/1193517 [00:35<00:37, 16637.59it/s]\r 48%|████▊     | 567297/1193517 [00:35<00:37, 16805.20it/s]\r 48%|████▊     | 568979/1193517 [00:35<00:37, 16757.63it/s]\r 48%|████▊     | 570677/1193517 [00:35<00:37, 16823.02it/s]\r 48%|████▊     | 572360/1193517 [00:36<00:37, 16613.13it/s]\r 48%|████▊     | 574023/1193517 [00:36<00:37, 16529.50it/s]\r 48%|████▊     | 575716/1193517 [00:36<00:37, 16646.46it/s]\r 48%|████▊     | 577382/1193517 [00:36<00:37, 16514.41it/s]\r 49%|████▊     | 579063/1193517 [00:36<00:37, 16601.29it/s]\r 49%|████▊     | 580763/1193517 [00:36<00:36, 16718.88it/s]\r 49%|████▉     | 582478/1193517 [00:36<00:36, 16845.71it/s]\r 49%|████▉     | 584178/1193517 [00:36<00:36, 16891.24it/s]\r 49%|████▉     | 585868/1193517 [00:36<00:36, 16703.47it/s]\r 49%|████▉     | 587539/1193517 [00:37<00:36, 16686.28it/s]\r 49%|████▉     | 589209/1193517 [00:37<00:36, 16679.56it/s]\r 50%|████▉     | 590878/1193517 [00:37<00:36, 16620.25it/s]\r 50%|████▉     | 592541/1193517 [00:37<00:36, 16609.51it/s]\r 50%|████▉     | 594203/1193517 [00:37<00:36, 16435.21it/s]\r 50%|████▉     | 595847/1193517 [00:37<00:36, 16390.81it/s]\r 50%|█████     | 597487/1193517 [00:37<00:36, 16263.93it/s]\r 50%|█████     | 599114/1193517 [00:37<00:36, 16147.05it/s]\r 50%|█████     | 600775/1193517 [00:37<00:36, 16281.87it/s]\r 50%|█████     | 602404/1193517 [00:37<00:36, 16209.14it/s]\r 51%|█████     | 604061/1193517 [00:38<00:36, 16314.31it/s]\r 51%|█████     | 605720/1193517 [00:38<00:35, 16395.60it/s]\r 51%|█████     | 607360/1193517 [00:38<00:35, 16387.64it/s]\r 51%|█████     | 609021/1193517 [00:38<00:35, 16452.00it/s]\r 51%|█████     | 610667/1193517 [00:38<00:35, 16387.06it/s]\r 51%|█████▏    | 612333/1193517 [00:38<00:35, 16466.01it/s]\r 51%|█████▏    | 613997/1193517 [00:38<00:35, 16516.70it/s]\r 52%|█████▏    | 615671/1193517 [00:38<00:34, 16581.63it/s]\r 52%|█████▏    | 617330/1193517 [00:38<00:35, 16352.56it/s]\r 52%|█████▏    | 618967/1193517 [00:38<00:35, 16195.08it/s]\r 52%|█████▏    | 620588/1193517 [00:39<00:35, 16166.96it/s]\r 52%|█████▏    | 622206/1193517 [00:39<00:35, 16135.64it/s]\r 52%|█████▏    | 623820/1193517 [00:39<00:35, 16132.74it/s]\r 52%|█████▏    | 625487/1193517 [00:39<00:34, 16289.67it/s]\r 53%|█████▎    | 627117/1193517 [00:39<00:34, 16221.73it/s]\r 53%|█████▎    | 628765/1193517 [00:39<00:34, 16298.41it/s]\r 53%|█████▎    | 630423/1193517 [00:39<00:34, 16381.52it/s]\r 53%|█████▎    | 632109/1193517 [00:39<00:33, 16523.54it/s]\r 53%|█████▎    | 633797/1193517 [00:39<00:33, 16627.80it/s]\r 53%|█████▎    | 635460/1193517 [00:39<00:33, 16544.75it/s]\r 53%|█████▎    | 637115/1193517 [00:40<00:34, 16339.53it/s]\r 54%|█████▎    | 638750/1193517 [00:40<00:34, 16243.60it/s]\r 54%|█████▎    | 640375/1193517 [00:40<00:34, 16216.35it/s]\r 54%|█████▍    | 641997/1193517 [00:40<00:34, 16059.48it/s]\r 54%|█████▍    | 643604/1193517 [00:40<00:34, 15943.36it/s]\r 54%|█████▍    | 645199/1193517 [00:40<00:34, 15812.41it/s]\r 54%|█████▍    | 646855/1193517 [00:40<00:34, 16031.91it/s]\r 54%|█████▍    | 648510/1193517 [00:40<00:33, 16183.29it/s]\r 54%|█████▍    | 650129/1193517 [00:40<00:33, 16112.54it/s]\r 55%|█████▍    | 651741/1193517 [00:40<00:33, 16022.33it/s]\r 55%|█████▍    | 653389/1193517 [00:41<00:33, 16155.95it/s]\r 55%|█████▍    | 655053/1193517 [00:41<00:33, 16297.92it/s]\r 55%|█████▌    | 656706/1193517 [00:41<00:32, 16364.62it/s]\r 55%|█████▌    | 658360/1193517 [00:41<00:32, 16416.30it/s]\r 55%|█████▌    | 660002/1193517 [00:41<00:32, 16310.54it/s]\r 55%|█████▌    | 661656/1193517 [00:41<00:32, 16376.23it/s]\r 56%|█████▌    | 663294/1193517 [00:41<00:32, 16250.83it/s]\r 56%|█████▌    | 664920/1193517 [00:41<00:32, 16139.51it/s]\r 56%|█████▌    | 666535/1193517 [00:41<00:32, 16105.57it/s]\r 56%|█████▌    | 668146/1193517 [00:41<00:32, 15978.03it/s]\r 56%|█████▌    | 669747/1193517 [00:42<00:32, 15985.95it/s]\r 56%|█████▋    | 671359/1193517 [00:42<00:32, 16024.58it/s]\r 56%|█████▋    | 673024/1193517 [00:42<00:32, 16210.47it/s]\r 57%|█████▋    | 674649/1193517 [00:42<00:31, 16219.92it/s]\r 57%|█████▋    | 676272/1193517 [00:42<00:32, 16137.22it/s]\r 57%|█████▋    | 677926/1193517 [00:42<00:31, 16255.05it/s]\r 57%|█████▋    | 679579/1193517 [00:42<00:31, 16335.85it/s]\r 57%|█████▋    | 681243/1193517 [00:42<00:31, 16425.30it/s]\r 57%|█████▋    | 682905/1193517 [00:42<00:30, 16482.71it/s]\r 57%|█████▋    | 684557/1193517 [00:42<00:30, 16492.89it/s]\r 57%|█████▋    | 686207/1193517 [00:43<00:30, 16388.20it/s]\r 58%|█████▊    | 687847/1193517 [00:43<00:31, 16272.39it/s]\r 58%|█████▊    | 689475/1193517 [00:43<00:31, 16184.74it/s]\r 58%|█████▊    | 691094/1193517 [00:43<00:31, 16136.18it/s]\r 58%|█████▊    | 692708/1193517 [00:43<00:31, 16062.60it/s]\r 58%|█████▊    | 694370/1193517 [00:43<00:30, 16226.77it/s]\r 58%|█████▊    | 696023/1193517 [00:43<00:30, 16314.21it/s]\r 58%|█████▊    | 697655/1193517 [00:43<00:30, 16263.90it/s]\r 59%|█████▊    | 699282/1193517 [00:43<00:33, 14718.70it/s]\r 59%|█████▊    | 700922/1193517 [00:44<00:32, 15184.05it/s]\r 59%|█████▉    | 702590/1193517 [00:44<00:31, 15607.10it/s]\r 59%|█████▉    | 704209/1193517 [00:44<00:31, 15773.54it/s]\r 59%|█████▉    | 705871/1193517 [00:44<00:30, 16018.41it/s]\r 59%|█████▉    | 707542/1193517 [00:44<00:29, 16220.62it/s]\r 59%|█████▉    | 709172/1193517 [00:44<00:30, 16083.30it/s]\r 60%|█████▉    | 710787/1193517 [00:44<00:29, 16102.09it/s]\r 60%|█████▉    | 712404/1193517 [00:44<00:29, 16120.82it/s]\r 60%|█████▉    | 714019/1193517 [00:44<00:29, 16111.56it/s]\r 60%|█████▉    | 715636/1193517 [00:44<00:29, 16128.75it/s]\r 60%|██████    | 717251/1193517 [00:45<00:29, 16095.79it/s]\r 60%|██████    | 718882/1193517 [00:45<00:29, 16158.87it/s]\r 60%|██████    | 720538/1193517 [00:45<00:29, 16278.09it/s]\r 61%|██████    | 722199/1193517 [00:45<00:28, 16375.12it/s]\r 61%|██████    | 723837/1193517 [00:45<00:28, 16315.27it/s]\r 61%|██████    | 725469/1193517 [00:45<00:28, 16198.33it/s]\r 61%|██████    | 727135/1193517 [00:45<00:28, 16333.19it/s]\r 61%|██████    | 728808/1193517 [00:45<00:28, 16450.04it/s]\r 61%|██████    | 730480/1193517 [00:45<00:28, 16530.09it/s]\r 61%|██████▏   | 732151/1193517 [00:45<00:27, 16582.15it/s]\r 61%|██████▏   | 733810/1193517 [00:46<00:28, 16258.08it/s]\r 62%|██████▏   | 735438/1193517 [00:46<00:28, 16121.65it/s]\r 62%|██████▏   | 737053/1193517 [00:46<00:28, 16129.45it/s]\r 62%|██████▏   | 738719/1193517 [00:46<00:27, 16286.05it/s]\r 62%|██████▏   | 740349/1193517 [00:46<00:27, 16236.17it/s]\r 62%|██████▏   | 742006/1193517 [00:46<00:27, 16332.79it/s]\r 62%|██████▏   | 743678/1193517 [00:46<00:27, 16447.47it/s]\r 62%|██████▏   | 745357/1193517 [00:46<00:27, 16547.77it/s]\r 63%|██████▎   | 747022/1193517 [00:46<00:26, 16576.34it/s]\r 63%|██████▎   | 748680/1193517 [00:46<00:27, 16419.05it/s]\r 63%|██████▎   | 750333/1193517 [00:47<00:26, 16450.63it/s]\r 63%|██████▎   | 751979/1193517 [00:47<00:27, 16296.86it/s]\r 63%|██████▎   | 753639/1193517 [00:47<00:26, 16385.96it/s]\r 63%|██████▎   | 755279/1193517 [00:47<00:26, 16266.58it/s]\r 63%|██████▎   | 756907/1193517 [00:47<00:26, 16226.05it/s]\r 64%|██████▎   | 758536/1193517 [00:47<00:26, 16242.28it/s]\r 64%|██████▎   | 760161/1193517 [00:47<00:26, 16163.79it/s]\r 64%|██████▍   | 761840/1193517 [00:47<00:26, 16348.15it/s]\r 64%|██████▍   | 763521/1193517 [00:47<00:26, 16485.16it/s]\r 64%|██████▍   | 765221/1193517 [00:47<00:25, 16636.80it/s]\r 64%|██████▍   | 766913/1193517 [00:48<00:25, 16720.26it/s]\r 64%|██████▍   | 768586/1193517 [00:48<00:25, 16629.04it/s]\r 65%|██████▍   | 770250/1193517 [00:48<00:25, 16507.02it/s]\r 65%|██████▍   | 771925/1193517 [00:48<00:25, 16578.41it/s]\r 65%|██████▍   | 773601/1193517 [00:48<00:25, 16631.82it/s]\r 65%|██████▍   | 775287/1193517 [00:48<00:25, 16697.41it/s]\r 65%|██████▌   | 776957/1193517 [00:48<00:25, 16461.21it/s]\r 65%|██████▌   | 778604/1193517 [00:48<00:25, 16050.89it/s]\r 65%|██████▌   | 780212/1193517 [00:48<00:25, 16030.73it/s]\r 66%|██████▌   | 781817/1193517 [00:48<00:25, 16031.65it/s]\r 66%|██████▌   | 783478/1193517 [00:49<00:25, 16202.12it/s]\r 66%|██████▌   | 785100/1193517 [00:49<00:25, 16137.39it/s]\r 66%|██████▌   | 786731/1193517 [00:49<00:25, 16186.44it/s]\r 66%|██████▌   | 788388/1193517 [00:49<00:24, 16299.13it/s]\r 66%|██████▌   | 790047/1193517 [00:49<00:24, 16383.60it/s]\r 66%|██████▋   | 791709/1193517 [00:49<00:24, 16453.55it/s]\r 66%|██████▋   | 793355/1193517 [00:49<00:24, 16326.11it/s]\r 67%|██████▋   | 795012/1193517 [00:49<00:24, 16396.23it/s]\r 67%|██████▋   | 796671/1193517 [00:49<00:24, 16453.89it/s]\r 67%|██████▋   | 798331/1193517 [00:49<00:23, 16494.69it/s]\r 67%|██████▋   | 799981/1193517 [00:50<00:24, 16379.14it/s]\r 67%|██████▋   | 801620/1193517 [00:50<00:24, 16131.88it/s]\r 67%|██████▋   | 803235/1193517 [00:50<00:24, 16074.07it/s]\r 67%|██████▋   | 804844/1193517 [00:50<00:24, 16038.54it/s]\r 68%|██████▊   | 806449/1193517 [00:50<00:24, 15956.38it/s]\r 68%|██████▊   | 808075/1193517 [00:50<00:24, 16044.71it/s]\r 68%|██████▊   | 809680/1193517 [00:50<00:24, 15984.95it/s]\r 68%|██████▊   | 811336/1193517 [00:50<00:23, 16153.43it/s]\r 68%|██████▊   | 812996/1193517 [00:50<00:23, 16286.36it/s]\r 68%|██████▊   | 814653/1193517 [00:50<00:23, 16370.27it/s]\r 68%|██████▊   | 816310/1193517 [00:51<00:22, 16427.68it/s]\r 69%|██████▊   | 817970/1193517 [00:51<00:22, 16476.77it/s]\r 69%|██████▊   | 819630/1193517 [00:51<00:22, 16511.83it/s]\r 69%|██████▉   | 821290/1193517 [00:51<00:22, 16535.63it/s]\r 69%|██████▉   | 822948/1193517 [00:51<00:22, 16547.69it/s]\r 69%|██████▉   | 824603/1193517 [00:51<00:22, 16378.96it/s]\r 69%|██████▉   | 826246/1193517 [00:51<00:22, 16391.74it/s]\r 69%|██████▉   | 827903/1193517 [00:51<00:22, 16442.10it/s]\r 70%|██████▉   | 829548/1193517 [00:51<00:22, 16281.24it/s]\r 70%|██████▉   | 831212/1193517 [00:51<00:22, 16386.21it/s]\r 70%|██████▉   | 832852/1193517 [00:52<00:22, 16352.52it/s]\r 70%|██████▉   | 834513/1193517 [00:52<00:21, 16426.62it/s]\r 70%|███████   | 836156/1193517 [00:52<00:21, 16363.64it/s]\r 70%|███████   | 837839/1193517 [00:52<00:21, 16500.58it/s]\r 70%|███████   | 839512/1193517 [00:52<00:21, 16566.96it/s]\r 70%|███████   | 841185/1193517 [00:52<00:21, 16615.49it/s]\r 71%|███████   | 842847/1193517 [00:52<00:21, 16614.03it/s]\r 71%|███████   | 844509/1193517 [00:52<00:21, 16490.91it/s]\r 71%|███████   | 846165/1193517 [00:52<00:21, 16509.39it/s]\r 71%|███████   | 847817/1193517 [00:52<00:21, 16305.42it/s]\r 71%|███████   | 849449/1193517 [00:53<00:21, 16198.59it/s]\r 71%|███████▏  | 851080/1193517 [00:53<00:21, 16230.60it/s]\r 71%|███████▏  | 852747/1193517 [00:53<00:20, 16360.20it/s]\r 72%|███████▏  | 854413/1193517 [00:53<00:20, 16448.88it/s]\r 72%|███████▏  | 856085/1193517 [00:53<00:20, 16527.75it/s]\r 72%|███████▏  | 857739/1193517 [00:53<00:20, 16269.36it/s]\r 72%|███████▏  | 859402/1193517 [00:53<00:20, 16375.82it/s]\r 72%|███████▏  | 861063/1193517 [00:53<00:20, 16445.13it/s]\r 72%|███████▏  | 862750/1193517 [00:53<00:19, 16569.69it/s]\r 72%|███████▏  | 864428/1193517 [00:54<00:19, 16630.95it/s]\r 73%|███████▎  | 866092/1193517 [00:54<00:20, 16352.43it/s]\r 73%|███████▎  | 867729/1193517 [00:54<00:19, 16331.43it/s]\r 73%|███████▎  | 869364/1193517 [00:54<00:19, 16227.18it/s]\r 73%|███████▎  | 870988/1193517 [00:54<00:19, 16179.51it/s]\r 73%|███████▎  | 872640/1193517 [00:54<00:19, 16278.41it/s]\r 73%|███████▎  | 874269/1193517 [00:54<00:19, 16203.42it/s]\r 73%|███████▎  | 875935/1193517 [00:54<00:19, 16336.10it/s]\r 74%|███████▎  | 877608/1193517 [00:54<00:19, 16452.97it/s]\r 74%|███████▎  | 879289/1193517 [00:54<00:18, 16557.62it/s]\r 74%|███████▍  | 880975/1193517 [00:55<00:18, 16645.60it/s]\r 74%|███████▍  | 882640/1193517 [00:55<00:18, 16443.88it/s]\r 74%|███████▍  | 884309/1193517 [00:55<00:18, 16514.47it/s]\r 74%|███████▍  | 885961/1193517 [00:55<00:18, 16433.98it/s]\r 74%|███████▍  | 887623/1193517 [00:55<00:18, 16487.13it/s]\r 75%|███████▍  | 889273/1193517 [00:55<00:18, 16410.59it/s]\r 75%|███████▍  | 890935/1193517 [00:55<00:18, 16471.18it/s]\r 75%|███████▍  | 892605/1193517 [00:55<00:18, 16538.23it/s]\r 75%|███████▍  | 894266/1193517 [00:55<00:18, 16559.38it/s]\r 75%|███████▌  | 895926/1193517 [00:55<00:17, 16568.50it/s]\r 75%|███████▌  | 897583/1193517 [00:56<00:18, 16287.48it/s]\r 75%|███████▌  | 899256/1193517 [00:56<00:17, 16417.40it/s]\r 75%|███████▌  | 900925/1193517 [00:56<00:17, 16497.91it/s]\r 76%|███████▌  | 902576/1193517 [00:56<00:17, 16343.05it/s]\r 76%|███████▌  | 904243/1193517 [00:56<00:17, 16438.63it/s]\r 76%|███████▌  | 905900/1193517 [00:56<00:17, 16476.50it/s]\r 76%|███████▌  | 907549/1193517 [00:56<00:17, 16364.82it/s]\r 76%|███████▌  | 909186/1193517 [00:56<00:17, 16239.99it/s]\r 76%|███████▋  | 910811/1193517 [00:56<00:17, 16146.71it/s]\r 76%|███████▋  | 912441/1193517 [00:56<00:17, 16191.65it/s]\r 77%|███████▋  | 914104/1193517 [00:57<00:17, 16320.05it/s]\r 77%|███████▋  | 915737/1193517 [00:57<00:17, 16316.64it/s]\r 77%|███████▋  | 917434/1193517 [00:57<00:16, 16509.40it/s]\r 77%|███████▋  | 919133/1193517 [00:57<00:16, 16650.36it/s]\r 77%|███████▋  | 920799/1193517 [00:57<00:16, 16605.17it/s]\r 77%|███████▋  | 922466/1193517 [00:57<00:16, 16623.80it/s]\r 77%|███████▋  | 924129/1193517 [00:57<00:16, 16620.38it/s]\r 78%|███████▊  | 925792/1193517 [00:57<00:16, 16592.14it/s]\r 78%|███████▊  | 927463/1193517 [00:57<00:16, 16624.52it/s]\r 78%|███████▊  | 929129/1193517 [00:57<00:15, 16634.19it/s]\r 78%|███████▊  | 930793/1193517 [00:58<00:15, 16482.97it/s]\r 78%|███████▊  | 932442/1193517 [00:58<00:15, 16383.13it/s]\r 78%|███████▊  | 934081/1193517 [00:58<00:16, 16187.90it/s]\r 78%|███████▊  | 935705/1193517 [00:58<00:15, 16202.12it/s]\r 79%|███████▊  | 937384/1193517 [00:58<00:15, 16373.68it/s]\r 79%|███████▊  | 939056/1193517 [00:58<00:15, 16474.57it/s]\r 79%|███████▉  | 940728/1193517 [00:58<00:15, 16544.74it/s]\r 79%|███████▉  | 942383/1193517 [00:58<00:15, 16422.11it/s]\r 79%|███████▉  | 944057/1193517 [00:58<00:15, 16513.84it/s]\r 79%|███████▉  | 945716/1193517 [00:58<00:14, 16535.71it/s]\r 79%|███████▉  | 947370/1193517 [00:59<00:14, 16536.56it/s]\r 80%|███████▉  | 949032/1193517 [00:59<00:14, 16559.97it/s]\r 80%|███████▉  | 950696/1193517 [00:59<00:14, 16582.81it/s]\r 80%|███████▉  | 952355/1193517 [00:59<00:14, 16570.90it/s]\r 80%|███████▉  | 954013/1193517 [00:59<00:14, 16557.61it/s]\r 80%|████████  | 955669/1193517 [00:59<00:14, 16545.82it/s]\r 80%|████████  | 957337/1193517 [00:59<00:14, 16585.37it/s]\r 80%|████████  | 958996/1193517 [00:59<00:14, 16490.06it/s]\r 80%|████████  | 960646/1193517 [00:59<00:14, 16184.11it/s]\r 81%|████████  | 962314/1193517 [00:59<00:14, 16324.72it/s]\r 81%|████████  | 963986/1193517 [01:00<00:13, 16439.25it/s]\r 81%|████████  | 965647/1193517 [01:00<00:13, 16488.10it/s]\r 81%|████████  | 967306/1193517 [01:00<00:13, 16516.19it/s]\r 81%|████████  | 968969/1193517 [01:00<00:13, 16549.55it/s]\r 81%|████████▏ | 970629/1193517 [01:00<00:13, 16563.65it/s]\r 81%|████████▏ | 972286/1193517 [01:00<00:13, 16564.14it/s]\r 82%|████████▏ | 973954/1193517 [01:00<00:13, 16598.03it/s]\r 82%|████████▏ | 975614/1193517 [01:00<00:13, 16293.54it/s]\r 82%|████████▏ | 977245/1193517 [01:00<00:13, 16178.78it/s]\r 82%|████████▏ | 978864/1193517 [01:00<00:13, 16142.11it/s]\r 82%|████████▏ | 980493/1193517 [01:01<00:13, 16182.88it/s]\r 82%|████████▏ | 982161/1193517 [01:01<00:12, 16327.99it/s]\r 82%|████████▏ | 983827/1193517 [01:01<00:12, 16424.88it/s]\r 83%|████████▎ | 985470/1193517 [01:01<00:12, 16320.15it/s]\r 83%|████████▎ | 987143/1193517 [01:01<00:12, 16441.68it/s]\r 83%|████████▎ | 988805/1193517 [01:01<00:12, 16492.33it/s]\r 83%|████████▎ | 990469/1193517 [01:01<00:12, 16534.96it/s]\r 83%|████████▎ | 992123/1193517 [01:01<00:12, 16400.69it/s]\r 83%|████████▎ | 993764/1193517 [01:01<00:12, 16323.05it/s]\r 83%|████████▎ | 995430/1193517 [01:01<00:12, 16420.56it/s]\r 84%|████████▎ | 997073/1193517 [01:02<00:12, 16237.40it/s]\r 84%|████████▎ | 998698/1193517 [01:02<00:12, 16158.42it/s]\r 84%|████████▍ | 1000315/1193517 [01:02<00:12, 16096.10it/s]\r 84%|████████▍ | 1001925/1193517 [01:02<00:11, 16061.50it/s]\r 84%|████████▍ | 1003581/1193517 [01:02<00:11, 16206.40it/s]\r 84%|████████▍ | 1005202/1193517 [01:02<00:11, 16019.97it/s]\r 84%|████████▍ | 1006857/1193517 [01:02<00:11, 16176.50it/s]\r 84%|████████▍ | 1008518/1193517 [01:02<00:11, 16305.11it/s]\r 85%|████████▍ | 1010180/1193517 [01:02<00:11, 16398.36it/s]\r 85%|████████▍ | 1011821/1193517 [01:02<00:11, 16339.81it/s]\r 85%|████████▍ | 1013459/1193517 [01:03<00:11, 16350.52it/s]\r 85%|████████▌ | 1015119/1193517 [01:03<00:10, 16423.25it/s]\r 85%|████████▌ | 1016777/1193517 [01:03<00:10, 16469.80it/s]\r 85%|████████▌ | 1018432/1193517 [01:03<00:10, 16493.11it/s]\r 85%|████████▌ | 1020095/1193517 [01:03<00:10, 16532.41it/s]\r 86%|████████▌ | 1021749/1193517 [01:03<00:10, 16361.86it/s]\r 86%|████████▌ | 1023386/1193517 [01:03<00:10, 16192.24it/s]\r 86%|████████▌ | 1025030/1193517 [01:03<00:10, 16263.11it/s]\r 86%|████████▌ | 1026696/1193517 [01:03<00:10, 16378.64it/s]\r 86%|████████▌ | 1028367/1193517 [01:03<00:10, 16475.22it/s]\r 86%|████████▋ | 1030015/1193517 [01:04<00:10, 16324.75it/s]\r 86%|████████▋ | 1031677/1193517 [01:04<00:09, 16411.20it/s]\r 87%|████████▋ | 1033339/1193517 [01:04<00:09, 16471.51it/s]\r 87%|████████▋ | 1035003/1193517 [01:04<00:09, 16521.10it/s]\r 87%|████████▋ | 1036667/1193517 [01:04<00:09, 16554.57it/s]\r 87%|████████▋ | 1038323/1193517 [01:04<00:09, 16496.91it/s]\r 87%|████████▋ | 1039973/1193517 [01:04<00:09, 16454.64it/s]\r 87%|████████▋ | 1041619/1193517 [01:04<00:09, 16441.36it/s]\r 87%|████████▋ | 1043264/1193517 [01:04<00:09, 16263.29it/s]\r 88%|████████▊ | 1044915/1193517 [01:05<00:09, 16334.04it/s]\r 88%|████████▊ | 1046549/1193517 [01:05<00:09, 16075.55it/s]\r 88%|████████▊ | 1048158/1193517 [01:05<00:09, 16035.80it/s]\r 88%|████████▊ | 1049796/1193517 [01:05<00:08, 16135.36it/s]\r 88%|████████▊ | 1051459/1193517 [01:05<00:08, 16280.90it/s]\r 88%|████████▊ | 1053088/1193517 [01:05<00:08, 16110.80it/s]\r 88%|████████▊ | 1054771/1193517 [01:05<00:08, 16321.56it/s]\r 89%|████████▊ | 1056437/1193517 [01:05<00:08, 16421.75it/s]\r 89%|████████▊ | 1058120/1193517 [01:05<00:08, 16542.65it/s]\r 89%|████████▉ | 1059807/1193517 [01:05<00:08, 16638.93it/s]\r 89%|████████▉ | 1061484/1193517 [01:06<00:07, 16676.85it/s]\r 89%|████████▉ | 1063161/1193517 [01:06<00:07, 16703.67it/s]\r 89%|████████▉ | 1064832/1193517 [01:06<00:07, 16667.97it/s]\r 89%|████████▉ | 1066499/1193517 [01:06<00:07, 16376.76it/s]\r 89%|████████▉ | 1068138/1193517 [01:06<00:07, 16284.24it/s]\r 90%|████████▉ | 1069768/1193517 [01:06<00:07, 16253.98it/s]\r 90%|████████▉ | 1071434/1193517 [01:06<00:07, 16374.13it/s]\r 90%|████████▉ | 1073094/1193517 [01:06<00:07, 16439.69it/s]\r 90%|█████████ | 1074739/1193517 [01:06<00:07, 16319.53it/s]\r 90%|█████████ | 1076409/1193517 [01:06<00:07, 16431.09it/s]\r 90%|█████████ | 1078079/1193517 [01:07<00:06, 16508.87it/s]\r 90%|█████████ | 1079731/1193517 [01:07<00:06, 16467.01it/s]\r 91%|█████████ | 1081378/1193517 [01:07<00:06, 16432.76it/s]\r 91%|█████████ | 1083043/1193517 [01:07<00:06, 16495.86it/s]\r 91%|█████████ | 1084693/1193517 [01:07<00:06, 16212.08it/s]\r 91%|█████████ | 1086316/1193517 [01:07<00:06, 16194.83it/s]\r 91%|█████████ | 1087937/1193517 [01:07<00:06, 16182.35it/s]\r 91%|█████████▏| 1089556/1193517 [01:07<00:06, 16095.28it/s]\r 91%|█████████▏| 1091196/1193517 [01:07<00:06, 16184.20it/s]\r 92%|█████████▏| 1092815/1193517 [01:07<00:06, 15993.03it/s]\r 92%|█████████▏| 1094476/1193517 [01:08<00:06, 16173.22it/s]\r 92%|█████████▏| 1096141/1193517 [01:08<00:05, 16314.53it/s]\r 92%|█████████▏| 1097792/1193517 [01:08<00:05, 16371.82it/s]\r 92%|█████████▏| 1099430/1193517 [01:08<00:05, 16253.24it/s]\r 92%|█████████▏| 1101098/1193517 [01:08<00:05, 16377.86it/s]\r 92%|█████████▏| 1102759/1193517 [01:08<00:05, 16445.49it/s]\r 93%|█████████▎| 1104410/1193517 [01:08<00:05, 16462.55it/s]\r 93%|█████████▎| 1106068/1193517 [01:08<00:05, 16496.35it/s]\r 93%|█████████▎| 1107726/1193517 [01:08<00:05, 16519.22it/s]\r 93%|█████████▎| 1109379/1193517 [01:08<00:05, 16400.10it/s]\r 93%|█████████▎| 1111020/1193517 [01:09<00:05, 16370.90it/s]\r 93%|█████████▎| 1112658/1193517 [01:09<00:05, 16144.54it/s]\r 93%|█████████▎| 1114278/1193517 [01:09<00:04, 16158.85it/s]\r 94%|█████████▎| 1115943/1193517 [01:09<00:04, 16303.34it/s]\r 94%|█████████▎| 1117607/1193517 [01:09<00:04, 16400.66it/s]\r 94%|█████████▍| 1119270/1193517 [01:09<00:04, 16465.85it/s]\r 94%|█████████▍| 1120933/1193517 [01:09<00:04, 16514.65it/s]\r 94%|█████████▍| 1122602/1193517 [01:09<00:04, 16565.95it/s]\r 94%|█████████▍| 1124259/1193517 [01:09<00:04, 16241.70it/s]\r 94%|█████████▍| 1125916/1193517 [01:09<00:04, 16338.14it/s]\r 94%|█████████▍| 1127563/1193517 [01:10<00:04, 16376.79it/s]\r 95%|█████████▍| 1129212/1193517 [01:10<00:03, 16408.76it/s]\r 95%|█████████▍| 1130854/1193517 [01:10<00:03, 16303.59it/s]\r 95%|█████████▍| 1132519/1193517 [01:10<00:03, 16405.12it/s]\r 95%|█████████▌| 1134180/1193517 [01:10<00:03, 16465.03it/s]\r 95%|█████████▌| 1135840/1193517 [01:10<00:03, 16503.66it/s]\r 95%|█████████▌| 1137497/1193517 [01:10<00:03, 16522.80it/s]\r 95%|█████████▌| 1139150/1193517 [01:10<00:03, 16356.67it/s]\r 96%|█████████▌| 1140807/1193517 [01:10<00:03, 16417.76it/s]\r 96%|█████████▌| 1142471/1193517 [01:10<00:03, 16483.66it/s]\r 96%|█████████▌| 1144131/1193517 [01:11<00:02, 16518.10it/s]\r 96%|█████████▌| 1145784/1193517 [01:11<00:02, 16397.10it/s]\r 96%|█████████▌| 1147425/1193517 [01:11<00:02, 16320.54it/s]\r 96%|█████████▋| 1149058/1193517 [01:11<00:02, 16181.67it/s]\r 96%|█████████▋| 1150687/1193517 [01:11<00:02, 16212.21it/s]\r 97%|█████████▋| 1152309/1193517 [01:11<00:02, 15981.34it/s]\r 97%|█████████▋| 1153926/1193517 [01:11<00:02, 16035.46it/s]\r 97%|█████████▋| 1155583/1193517 [01:11<00:02, 16193.12it/s]\r 97%|█████████▋| 1157260/1193517 [01:11<00:02, 16362.14it/s]\r 97%|█████████▋| 1158897/1193517 [01:11<00:02, 16289.95it/s]\r 97%|█████████▋| 1160572/1193517 [01:12<00:02, 16425.82it/s]\r 97%|█████████▋| 1162237/1193517 [01:12<00:01, 16492.52it/s]\r 98%|█████████▊| 1163914/1193517 [01:12<00:01, 16573.43it/s]\r 98%|█████████▊| 1165572/1193517 [01:12<00:01, 16575.01it/s]\r 98%|█████████▊| 1167246/1193517 [01:12<00:01, 16621.54it/s]\r 98%|█████████▊| 1168909/1193517 [01:12<00:01, 16442.08it/s]\r 98%|█████████▊| 1170554/1193517 [01:12<00:01, 16254.92it/s]\r 98%|█████████▊| 1172181/1193517 [01:12<00:01, 16132.12it/s]\r 98%|█████████▊| 1173795/1193517 [01:12<00:01, 16126.46it/s]\r 98%|█████████▊| 1175409/1193517 [01:12<00:01, 16083.91it/s]\r 99%|█████████▊| 1177073/1193517 [01:13<00:01, 16246.98it/s]\r 99%|█████████▉| 1178699/1193517 [01:13<00:01, 14499.68it/s]\r 99%|█████████▉| 1180184/1193517 [01:13<00:00, 14425.91it/s]\r 99%|█████████▉| 1181860/1193517 [01:13<00:00, 15078.43it/s]\r 99%|█████████▉| 1183540/1193517 [01:13<00:00, 15568.69it/s]\r 99%|█████████▉| 1185222/1193517 [01:13<00:00, 15930.97it/s]\r 99%|█████████▉| 1186896/1193517 [01:13<00:00, 16165.07it/s]\r100%|█████████▉| 1188571/1193517 [01:13<00:00, 16337.14it/s]\r100%|█████████▉| 1190244/1193517 [01:13<00:00, 16451.93it/s]\r100%|█████████▉| 1191901/1193517 [01:14<00:00, 16484.83it/s]\r100%|██████████| 1193517/1193517 [01:14<00:00, 16099.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["1123749 64 826239 1123749\n","1--loss_train\n","tensor(1614.2800, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.6444 0.6433 0.6447\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.6444 0.6433 0.6447\n","Text: 0.6444 0.6433 0.6447\n","G+T: 0.6444 0.6433 0.6447\n","G+U+T: 0.6444 0.6433 0.6447\n","Epoch: 0001 train_loss= 644460.2500 train_acc= 0.6444 val_loss= 80798.4531 val_acc= 0.6433 test_loss= 80566.6875 test_acc= 0.6447 F1-score=0.3920 time= 1988.2489\n","2--loss_train\n","tensor(1620.3666, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.6444 0.6433 0.6447\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.6444 0.6433 0.6447\n","Text: 0.6444 0.6433 0.6447\n","G+T: 0.6444 0.6433 0.6447\n","G+U+T: 0.6444 0.6433 0.6447\n","Epoch: 0002 train_loss= 639249.2500 train_acc= 0.6444 val_loss= 80702.0391 val_acc= 0.6433 test_loss= 80449.8984 test_acc= 0.6447 F1-score=0.3920 time= 1982.0639\n","3--loss_train\n","tensor(1607.6378, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.6444 0.6433 0.6447\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.6444 0.6433 0.6447\n","Text: 0.6444 0.6433 0.6447\n","G+T: 0.6444 0.6433 0.6447\n","G+U+T: 0.6444 0.6433 0.6447\n","Epoch: 0003 train_loss= 609662.2500 train_acc= 0.6444 val_loss= 78570.7188 val_acc= 0.6433 test_loss= 78297.8203 test_acc= 0.6447 F1-score=0.3920 time= 1944.8271\n","4--loss_train\n","tensor(1606.3846, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.7745 0.7167 0.7178\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.6444 0.6433 0.6447\n","Text: 0.6444 0.6433 0.6447\n","G+T: 0.6444 0.6433 0.6447\n","G+U+T: 0.6444 0.6433 0.6447\n","Epoch: 0004 train_loss= 545920.4375 train_acc= 0.6444 val_loss= 73554.0078 val_acc= 0.6433 test_loss= 73244.3516 test_acc= 0.6447 F1-score=0.3920 time= 1891.6731\n","5--loss_train\n","tensor(1598.4065, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9586 0.8702 0.872\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.6543 0.6448 0.6461\n","Text: 0.6444 0.6433 0.6447\n","G+T: 0.6451 0.6433 0.6447\n","G+U+T: 0.6444 0.6433 0.6447\n","Epoch: 0005 train_loss= 438472.6250 train_acc= 0.6444 val_loss= 64256.0195 val_acc= 0.6433 test_loss= 63909.8945 test_acc= 0.6447 F1-score=0.3920 time= 1969.1434\n","6--loss_train\n","tensor(1621.0148, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9666 0.8781 0.8806\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.956 0.8653 0.8671\n","Text: 0.6444 0.6433 0.6447\n","G+T: 0.9525 0.8579 0.8602\n","G+U+T: 0.6593 0.6452 0.6463\n","Epoch: 0006 train_loss= 318552.5625 train_acc= 0.6593 val_loss= 53717.3945 val_acc= 0.6452 test_loss= 53343.4844 test_acc= 0.6463 F1-score=0.3970 time= 1921.7555\n","7--loss_train\n","tensor(1594.5562, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9685 0.8793 0.8821\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.966 0.8781 0.88\n","Text: 0.6444 0.6433 0.6447\n","G+T: 0.9654 0.8773 0.8794\n","G+U+T: 0.9537 0.8612 0.8633\n","Epoch: 0007 train_loss= 219034.4688 train_acc= 0.9537 val_loss= 44885.9375 val_acc= 0.8612 test_loss= 44493.7148 test_acc= 0.8633 F1-score=0.8355 time= 1912.5596\n","8--loss_train\n","tensor(1602.5278, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9686 0.8796 0.8819\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9667 0.8788 0.8808\n","Text: 0.6444 0.6433 0.6447\n","G+T: 0.9662 0.8784 0.8806\n","G+U+T: 0.9619 0.8746 0.8763\n","Epoch: 0008 train_loss= 159138.2500 train_acc= 0.9619 val_loss= 39756.0469 val_acc= 0.8746 test_loss= 39382.3516 test_acc= 0.8763 F1-score=0.8532 time= 1962.2340\n","9--loss_train\n","tensor(1619.9249, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9684 0.8795 0.8818\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9677 0.8798 0.8818\n","Text: 0.6444 0.6433 0.6447\n","G+T: 0.9676 0.8796 0.8817\n","G+U+T: 0.9622 0.8749 0.8766\n","Epoch: 0009 train_loss= 130544.9766 train_acc= 0.9622 val_loss= 37683.4531 val_acc= 0.8749 test_loss= 37320.3242 test_acc= 0.8766 F1-score=0.8537 time= 1913.6990\n","10--loss_train\n","tensor(1599.0355, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9676 0.879 0.8808\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9659 0.8783 0.8806\n","Text: 0.6444 0.6433 0.6447\n","G+T: 0.9657 0.8783 0.8802\n","G+U+T: 0.9633 0.8762 0.8781\n","Epoch: 0010 train_loss= 117996.5469 train_acc= 0.9633 val_loss= 37377.3711 val_acc= 0.8762 test_loss= 36987.8008 test_acc= 0.8781 F1-score=0.8557 time= 1948.4950\n","11--loss_train\n","tensor(1506.3722, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9674 0.8784 0.8797\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9662 0.8785 0.8802\n","Text: 0.6778 0.6769 0.6775\n","G+T: 0.965 0.8808 0.8828\n","G+U+T: 0.9618 0.8748 0.8766\n","Epoch: 0011 train_loss= 110623.6172 train_acc= 0.9618 val_loss= 35537.9062 val_acc= 0.8748 test_loss= 35200.1172 test_acc= 0.8766 F1-score=0.8540 time= 1932.1865\n","12--loss_train\n","tensor(1357.5142, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9627 0.8886 0.8907\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9602 0.882 0.8844\n","Text: 0.7594 0.7592 0.7597\n","G+T: 0.9559 0.8954 0.8959\n","G+U+T: 0.9522 0.8911 0.8914\n","Epoch: 0012 train_loss= 131243.7188 train_acc= 0.9522 val_loss= 34378.8398 val_acc= 0.8911 test_loss= 34176.7969 test_acc= 0.8914 F1-score=0.8757 time= 1951.6571\n","13--loss_train\n","tensor(1255.5873, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9666 0.9002 0.9015\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9654 0.8973 0.8988\n","Text: 0.7695 0.7662 0.77\n","G+T: 0.9591 0.902 0.9024\n","G+U+T: 0.9532 0.8946 0.8953\n","Epoch: 0013 train_loss= 125386.5078 train_acc= 0.9532 val_loss= 34295.0898 val_acc= 0.8946 test_loss= 33982.8320 test_acc= 0.8953 F1-score=0.8800 time= 1884.2102\n","14--loss_train\n","tensor(1142.1731, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9675 0.9045 0.9057\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9659 0.9034 0.9036\n","Text: 0.7813 0.7792 0.7802\n","G+T: 0.9597 0.9059 0.9053\n","G+U+T: 0.9558 0.9035 0.9024\n","Epoch: 0014 train_loss= 115737.2578 train_acc= 0.9558 val_loss= 32890.5000 val_acc= 0.9035 test_loss= 32839.0234 test_acc= 0.9024 F1-score=0.8899 time= 1955.0436\n","15--loss_train\n","tensor(1035.6361, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9678 0.9065 0.9067\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9666 0.9061 0.9062\n","Text: 0.7886 0.7857 0.7883\n","G+T: 0.9621 0.9085 0.9085\n","G+U+T: 0.9581 0.9054 0.905\n","Epoch: 0015 train_loss= 108988.4531 train_acc= 0.9581 val_loss= 32984.2383 val_acc= 0.9054 test_loss= 32913.5469 test_acc= 0.9050 F1-score=0.8930 time= 1914.8768\n","16--loss_train\n","tensor(923.6108, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9678 0.9074 0.9083\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9666 0.9074 0.9077\n","Text: 0.7935 0.7912 0.7933\n","G+T: 0.9634 0.9103 0.9107\n","G+U+T: 0.9599 0.9077 0.9076\n","Epoch: 0016 train_loss= 102713.6875 train_acc= 0.9599 val_loss= 32717.9297 val_acc= 0.9077 test_loss= 32590.1445 test_acc= 0.9076 F1-score=0.8961 time= 1947.8932\n","17--loss_train\n","tensor(895.2821, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9679 0.9077 0.9082\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9665 0.9076 0.9078\n","Text: 0.7959 0.7929 0.7954\n","G+T: 0.9633 0.9113 0.9108\n","G+U+T: 0.9589 0.9073 0.9067\n","Epoch: 0017 train_loss= 106637.6641 train_acc= 0.9589 val_loss= 33841.0547 val_acc= 0.9073 test_loss= 33753.9531 test_acc= 0.9067 F1-score=0.8947 time= 1918.5794\n","18--loss_train\n","tensor(811.2894, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9674 0.9082 0.9088\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9663 0.908 0.9083\n","Text: 0.7977 0.7963 0.7972\n","G+T: 0.9629 0.9114 0.9113\n","G+U+T: 0.958 0.907 0.9068\n","Epoch: 0018 train_loss= 109177.7500 train_acc= 0.9580 val_loss= 34772.6094 val_acc= 0.9070 test_loss= 34558.9375 test_acc= 0.9068 F1-score=0.8944 time= 1942.3831\n","19--loss_train\n","tensor(832.4734, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9676 0.9084 0.9086\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9663 0.9084 0.9084\n","Text: 0.8043 0.8017 0.8024\n","G+T: 0.9615 0.911 0.9109\n","G+U+T: 0.9567 0.9074 0.9072\n","Epoch: 0019 train_loss= 115295.2812 train_acc= 0.9567 val_loss= 35887.6797 val_acc= 0.9074 test_loss= 35752.2812 test_acc= 0.9072 F1-score=0.8953 time= 1884.8935\n","20--loss_train\n","tensor(757.7083, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9671 0.9079 0.9087\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9663 0.9092 0.9098\n","Text: 0.8032 0.8002 0.8029\n","G+T: 0.9639 0.9131 0.9136\n","G+U+T: 0.9613 0.9114 0.9117\n","Epoch: 0020 train_loss= 97713.1953 train_acc= 0.9613 val_loss= 33038.7578 val_acc= 0.9114 test_loss= 32843.6133 test_acc= 0.9117 F1-score=0.9011 time= 1937.9026\n","21--loss_train\n","tensor(755.9231, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9673 0.909 0.9097\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9659 0.9085 0.9095\n","Text: 0.807 0.8054 0.8053\n","G+T: 0.9622 0.9119 0.9125\n","G+U+T: 0.9577 0.9079 0.908\n","Epoch: 0021 train_loss= 114998.0000 train_acc= 0.9577 val_loss= 36266.6055 val_acc= 0.9079 test_loss= 35966.4180 test_acc= 0.9080 F1-score=0.8960 time= 1916.2144\n","22--loss_train\n","tensor(695.2083, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9666 0.9085 0.9094\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9663 0.9091 0.9102\n","Text: 0.8083 0.8057 0.8077\n","G+T: 0.9652 0.9144 0.9147\n","G+U+T: 0.9626 0.9122 0.9125\n","Epoch: 0022 train_loss= 93552.8594 train_acc= 0.9626 val_loss= 32640.7012 val_acc= 0.9122 test_loss= 32397.1680 test_acc= 0.9125 F1-score=0.9021 time= 1946.6916\n","23--loss_train\n","tensor(648.9388, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9672 0.9096 0.9102\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9659 0.9091 0.91\n","Text: 0.8125 0.8102 0.8123\n","G+T: 0.964 0.9143 0.9143\n","G+U+T: 0.96 0.9109 0.9112\n","Epoch: 0023 train_loss= 106998.7500 train_acc= 0.9600 val_loss= 34690.1367 val_acc= 0.9109 test_loss= 34442.7070 test_acc= 0.9112 F1-score=0.9002 time= 1902.2706\n","24--loss_train\n","tensor(681.4164, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9662 0.9085 0.9091\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9661 0.909 0.9103\n","Text: 0.8129 0.811 0.8106\n","G+T: 0.964 0.9141 0.9149\n","G+U+T: 0.9594 0.9101 0.9106\n","Epoch: 0024 train_loss= 105493.5703 train_acc= 0.9594 val_loss= 34729.4688 val_acc= 0.9101 test_loss= 34507.7695 test_acc= 0.9106 F1-score=0.8992 time= 1945.8874\n","25--loss_train\n","tensor(661.4142, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9668 0.9097 0.9105\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9656 0.9094 0.9104\n","Text: 0.8138 0.8114 0.8132\n","G+T: 0.9642 0.915 0.9149\n","G+U+T: 0.961 0.9121 0.912\n","Epoch: 0025 train_loss= 106624.9844 train_acc= 0.9610 val_loss= 34494.7266 val_acc= 0.9121 test_loss= 34375.0781 test_acc= 0.9120 F1-score=0.9013 time= 1903.5244\n","26--loss_train\n","tensor(611.1024, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9658 0.9079 0.9092\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9659 0.9091 0.91\n","Text: 0.8165 0.8146 0.8155\n","G+T: 0.9648 0.9151 0.9154\n","G+U+T: 0.9604 0.9115 0.9114\n","Epoch: 0026 train_loss= 101701.1172 train_acc= 0.9604 val_loss= 34494.0430 val_acc= 0.9115 test_loss= 34242.0039 test_acc= 0.9114 F1-score=0.9002 time= 2060.3253\n","27--loss_train\n","tensor(600.6339, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9666 0.9102 0.9113\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9653 0.9094 0.9109\n","Text: 0.8192 0.8174 0.8181\n","G+T: 0.9639 0.9154 0.9157\n","G+U+T: 0.9606 0.913 0.9128\n","Epoch: 0027 train_loss= 109813.8125 train_acc= 0.9606 val_loss= 34738.6094 val_acc= 0.9130 test_loss= 34593.7109 test_acc= 0.9128 F1-score=0.9021 time= 2020.3293\n","28--loss_train\n","tensor(607.7695, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9653 0.9079 0.9087\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9659 0.9091 0.9101\n","Text: 0.8188 0.8173 0.8181\n","G+T: 0.9648 0.9155 0.9164\n","G+U+T: 0.9606 0.9119 0.9128\n","Epoch: 0028 train_loss= 100525.6719 train_acc= 0.9606 val_loss= 34406.7812 val_acc= 0.9119 test_loss= 34009.7031 test_acc= 0.9128 F1-score=0.9017 time= 2069.9165\n","29--loss_train\n","tensor(562.2606, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9663 0.911 0.912\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9649 0.9099 0.9113\n","Text: 0.8226 0.8208 0.8214\n","G+T: 0.9637 0.9161 0.9166\n","G+U+T: 0.9601 0.913 0.9134\n","Epoch: 0029 train_loss= 113478.4531 train_acc= 0.9601 val_loss= 35059.0703 val_acc= 0.9130 test_loss= 34824.2344 test_acc= 0.9134 F1-score=0.9026 time= 2023.2517\n","30--loss_train\n","tensor(561.4601, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.965 0.9081 0.9083\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9657 0.9094 0.9108\n","Text: 0.8236 0.8222 0.8225\n","G+T: 0.9662 0.9176 0.9179\n","G+U+T: 0.9632 0.9156 0.9151\n","Epoch: 0030 train_loss= 92799.8281 train_acc= 0.9632 val_loss= 32785.9180 val_acc= 0.9156 test_loss= 32646.6152 test_acc= 0.9151 F1-score=0.9048 time= 2079.0215\n","31--loss_train\n","tensor(528.4821, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9663 0.9118 0.9123\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9649 0.9104 0.9115\n","Text: 0.8248 0.8234 0.8239\n","G+T: 0.9634 0.9167 0.9166\n","G+U+T: 0.9596 0.9137 0.9136\n","Epoch: 0031 train_loss= 115866.5859 train_acc= 0.9596 val_loss= 35335.6523 val_acc= 0.9137 test_loss= 35156.8555 test_acc= 0.9136 F1-score=0.9028 time= 2020.3630\n","32--loss_train\n","tensor(512.0400, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9649 0.9084 0.9088\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9659 0.9097 0.9109\n","Text: 0.827 0.8252 0.8262\n","G+T: 0.9652 0.9175 0.9171\n","G+U+T: 0.9615 0.9147 0.9141\n","Epoch: 0032 train_loss= 99225.0859 train_acc= 0.9615 val_loss= 33811.9297 val_acc= 0.9147 test_loss= 33636.4219 test_acc= 0.9141 F1-score=0.9034 time= 2080.5625\n","33--loss_train\n","tensor(508.9459, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9661 0.9118 0.9127\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9647 0.9106 0.9116\n","Text: 0.8266 0.8256 0.8264\n","G+T: 0.9642 0.9177 0.9177\n","G+U+T: 0.9605 0.9146 0.9148\n","Epoch: 0033 train_loss= 113623.8359 train_acc= 0.9605 val_loss= 34496.4492 val_acc= 0.9146 test_loss= 34377.8008 test_acc= 0.9148 F1-score=0.9042 time= 2023.4151\n","34--loss_train\n","tensor(525.4485, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9646 0.9085 0.9091\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9658 0.9101 0.9115\n","Text: 0.8295 0.8274 0.8279\n","G+T: 0.9663 0.9193 0.9196\n","G+U+T: 0.9637 0.9173 0.917\n","Epoch: 0034 train_loss= 91777.4766 train_acc= 0.9637 val_loss= 32278.3398 val_acc= 0.9173 test_loss= 32145.0039 test_acc= 0.9170 F1-score=0.9071 time= 2081.9838\n","35--loss_train\n","tensor(555.3295, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.966 0.9122 0.9131\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9644 0.9114 0.9125\n","Text: 0.8305 0.8295 0.8295\n","G+T: 0.9647 0.9189 0.919\n","G+U+T: 0.9611 0.9161 0.9154\n","Epoch: 0035 train_loss= 111454.6016 train_acc= 0.9611 val_loss= 33823.1406 val_acc= 0.9161 test_loss= 33714.1367 test_acc= 0.9154 F1-score=0.9050 time= 1968.1130\n","36--loss_train\n","tensor(491.6915, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9644 0.9094 0.9098\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9657 0.9103 0.9119\n","Text: 0.8316 0.8299 0.8303\n","G+T: 0.966 0.9194 0.9195\n","G+U+T: 0.9619 0.9153 0.9155\n","Epoch: 0036 train_loss= 97864.1250 train_acc= 0.9619 val_loss= 33371.3672 val_acc= 0.9153 test_loss= 33094.3945 test_acc= 0.9155 F1-score=0.9050 time= 1974.3462\n","37--loss_train\n","tensor(496.9181, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9659 0.913 0.9133\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9644 0.9115 0.9123\n","Text: 0.8324 0.8298 0.8308\n","G+T: 0.9637 0.9189 0.9184\n","G+U+T: 0.9589 0.9137 0.9138\n","Epoch: 0037 train_loss= 121327.8750 train_acc= 0.9589 val_loss= 35292.5469 val_acc= 0.9137 test_loss= 35025.9023 test_acc= 0.9138 F1-score=0.9026 time= 1962.3478\n","38--loss_train\n","tensor(511.2457, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9644 0.9098 0.9103\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.966 0.911 0.912\n","Text: 0.8352 0.8337 0.8344\n","G+T: 0.9667 0.9211 0.9204\n","G+U+T: 0.9641 0.9179 0.9183\n","Epoch: 0038 train_loss= 92437.0938 train_acc= 0.9641 val_loss= 31841.9180 val_acc= 0.9179 test_loss= 31650.6562 test_acc= 0.9183 F1-score=0.9086 time= 1996.0829\n","39--loss_train\n","tensor(502.9528, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9658 0.9135 0.914\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9644 0.9117 0.9126\n","Text: 0.8356 0.8346 0.8343\n","G+T: 0.9641 0.9202 0.9192\n","G+U+T: 0.9601 0.9158 0.9159\n","Epoch: 0039 train_loss= 116732.1719 train_acc= 0.9601 val_loss= 34223.6406 val_acc= 0.9158 test_loss= 34125.7656 test_acc= 0.9159 F1-score=0.9054 time= 1929.0494\n","40--loss_train\n","tensor(474.4794, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9643 0.91 0.9102\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9656 0.9113 0.9116\n","Text: 0.8329 0.8306 0.8324\n","G+T: 0.9667 0.9214 0.9203\n","G+U+T: 0.9652 0.9196 0.9197\n","Epoch: 0040 train_loss= 87988.1484 train_acc= 0.9652 val_loss= 30873.9121 val_acc= 0.9196 test_loss= 30730.6152 test_acc= 0.9197 F1-score=0.9106 time= 1963.4185\n","41--loss_train\n","tensor(454.8822, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9659 0.9139 0.9146\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9639 0.9115 0.9121\n","Text: 0.8386 0.8379 0.8375\n","G+T: 0.9636 0.92 0.9194\n","G+U+T: 0.9593 0.9158 0.9154\n","Epoch: 0041 train_loss= 121667.5234 train_acc= 0.9593 val_loss= 34919.6367 val_acc= 0.9158 test_loss= 34927.4297 test_acc= 0.9154 F1-score=0.9046 time= 1908.1285\n","42--loss_train\n","tensor(420.0312, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.964 0.9107 0.9101\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9657 0.9112 0.9122\n","Text: 0.8378 0.8363 0.8365\n","G+T: 0.9664 0.9218 0.9219\n","G+U+T: 0.9645 0.92 0.9197\n","Epoch: 0042 train_loss= 90834.0312 train_acc= 0.9645 val_loss= 31071.5469 val_acc= 0.9200 test_loss= 31041.8965 test_acc= 0.9197 F1-score=0.9104 time= 1944.9731\n","43--loss_train\n","tensor(412.6113, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9659 0.9146 0.9147\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9645 0.9121 0.9132\n","Text: 0.8404 0.8385 0.8389\n","G+T: 0.9651 0.9219 0.921\n","G+U+T: 0.9613 0.9183 0.9175\n","Epoch: 0043 train_loss= 113124.1016 train_acc= 0.9613 val_loss= 33275.9453 val_acc= 0.9183 test_loss= 33324.3633 test_acc= 0.9175 F1-score=0.9073 time= 1912.0927\n","44--loss_train\n","tensor(477.5645, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9642 0.911 0.9105\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9656 0.9112 0.9123\n","Text: 0.841 0.8398 0.8394\n","G+T: 0.9661 0.9216 0.921\n","G+U+T: 0.9616 0.9171 0.9167\n","Epoch: 0044 train_loss= 100653.6797 train_acc= 0.9616 val_loss= 33173.4375 val_acc= 0.9171 test_loss= 33142.1523 test_acc= 0.9167 F1-score=0.9061 time= 1943.0959\n","45--loss_train\n","tensor(429.6932, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9657 0.915 0.9151\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9637 0.9114 0.912\n","Text: 0.8438 0.8413 0.8432\n","G+T: 0.9657 0.9227 0.9215\n","G+U+T: 0.962 0.919 0.9182\n","Epoch: 0045 train_loss= 110136.0000 train_acc= 0.9620 val_loss= 32689.7969 val_acc= 0.9190 test_loss= 32710.0781 test_acc= 0.9182 F1-score=0.9081 time= 1920.6072\n","46--loss_train\n","tensor(442.0273, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.964 0.9114 0.9112\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9656 0.9116 0.9129\n","Text: 0.842 0.8402 0.8404\n","G+T: 0.9652 0.9213 0.9212\n","G+U+T: 0.9602 0.9163 0.9161\n","Epoch: 0046 train_loss= 105621.7812 train_acc= 0.9602 val_loss= 33732.7422 val_acc= 0.9163 test_loss= 33701.8359 test_acc= 0.9161 F1-score=0.9053 time= 1940.1366\n","47--loss_train\n","tensor(409.6047, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9659 0.9161 0.9158\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9642 0.9122 0.9136\n","Text: 0.848 0.8457 0.8464\n","G+T: 0.9628 0.9209 0.9208\n","G+U+T: 0.9579 0.9163 0.9164\n","Epoch: 0047 train_loss= 126000.8438 train_acc= 0.9579 val_loss= 35248.3359 val_acc= 0.9163 test_loss= 35269.4141 test_acc= 0.9164 F1-score=0.9057 time= 1902.3283\n","48--loss_train\n","tensor(444.6816, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9641 0.9125 0.9109\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9656 0.9117 0.9132\n","Text: 0.847 0.8445 0.8451\n","G+T: 0.9672 0.9242 0.9238\n","G+U+T: 0.9649 0.9219 0.9212\n","Epoch: 0048 train_loss= 90511.7344 train_acc= 0.9649 val_loss= 30469.2949 val_acc= 0.9219 test_loss= 30494.3711 test_acc= 0.9212 F1-score=0.9120 time= 1946.3141\n","49--loss_train\n","tensor(458.4348, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9658 0.9164 0.9163\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.964 0.9124 0.9135\n","Text: 0.8497 0.8474 0.848\n","G+T: 0.9642 0.9231 0.9227\n","G+U+T: 0.9604 0.9195 0.9192\n","Epoch: 0049 train_loss= 116113.2188 train_acc= 0.9604 val_loss= 33286.6328 val_acc= 0.9195 test_loss= 33401.3984 test_acc= 0.9192 F1-score=0.9093 time= 1907.9887\n","50--loss_train\n","tensor(470.0248, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9639 0.9123 0.9111\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9657 0.9118 0.9131\n","Text: 0.8468 0.8441 0.8443\n","G+T: 0.9681 0.9253 0.9241\n","G+U+T: 0.9663 0.9232 0.9229\n","Epoch: 0050 train_loss= 85465.0312 train_acc= 0.9663 val_loss= 29494.2891 val_acc= 0.9232 test_loss= 29672.4277 test_acc= 0.9229 F1-score=0.9142 time= 1939.8789\n","51--loss_train\n","tensor(426.5578, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9658 0.9166 0.9167\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9641 0.9127 0.9134\n","Text: 0.8511 0.8489 0.8498\n","G+T: 0.963 0.9229 0.9223\n","G+U+T: 0.959 0.9191 0.9187\n","Epoch: 0051 train_loss= 122446.8438 train_acc= 0.9590 val_loss= 33925.4844 val_acc= 0.9191 test_loss= 34127.5117 test_acc= 0.9187 F1-score=0.9087 time= 1888.2025\n","52--loss_train\n","tensor(463.6178, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.964 0.9131 0.9124\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9654 0.9123 0.9131\n","Text: 0.8521 0.8503 0.8503\n","G+T: 0.967 0.9255 0.9247\n","G+U+T: 0.9644 0.9225 0.9224\n","Epoch: 0052 train_loss= 92252.5312 train_acc= 0.9644 val_loss= 30468.8438 val_acc= 0.9225 test_loss= 30647.6953 test_acc= 0.9224 F1-score=0.9135 time= 1950.0051\n","53--loss_train\n","tensor(411.0152, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9658 0.9168 0.9168\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.964 0.9131 0.9138\n","Text: 0.8532 0.8517 0.8517\n","G+T: 0.964 0.924 0.9232\n","G+U+T: 0.9599 0.9202 0.9195\n","Epoch: 0053 train_loss= 118508.9062 train_acc= 0.9599 val_loss= 33192.5234 val_acc= 0.9202 test_loss= 33436.3906 test_acc= 0.9195 F1-score=0.9096 time= 1899.2655\n","54--loss_train\n","tensor(387.1281, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9639 0.9137 0.9128\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9655 0.9122 0.9133\n","Text: 0.8552 0.853 0.8538\n","G+T: 0.9666 0.926 0.9252\n","G+U+T: 0.9638 0.9231 0.9224\n","Epoch: 0054 train_loss= 94129.4375 train_acc= 0.9638 val_loss= 30631.6738 val_acc= 0.9231 test_loss= 30845.5469 test_acc= 0.9224 F1-score=0.9133 time= 1949.1393\n","55--loss_train\n","tensor(428.3136, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9658 0.9176 0.9175\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9641 0.9132 0.9138\n","Text: 0.8535 0.8521 0.8509\n","G+T: 0.9632 0.9247 0.9235\n","G+U+T: 0.9594 0.9215 0.9202\n","Epoch: 0055 train_loss= 120065.1250 train_acc= 0.9594 val_loss= 33260.0469 val_acc= 0.9215 test_loss= 33625.7500 test_acc= 0.9202 F1-score=0.9106 time= 1890.2124\n","56--loss_train\n","tensor(438.0496, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9637 0.9136 0.9129\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9654 0.9123 0.9131\n","Text: 0.8568 0.8539 0.8556\n","G+T: 0.965 0.9255 0.9247\n","G+U+T: 0.9614 0.9219 0.9215\n","Epoch: 0056 train_loss= 102535.0156 train_acc= 0.9614 val_loss= 31913.8652 val_acc= 0.9219 test_loss= 32301.8906 test_acc= 0.9215 F1-score=0.9120 time= 1948.1499\n","57--loss_train\n","tensor(406.9341, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9658 0.9185 0.9175\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9641 0.9141 0.9143\n","Text: 0.8572 0.8544 0.8554\n","G+T: 0.9639 0.9251 0.9241\n","G+U+T: 0.9591 0.9208 0.9198\n","Epoch: 0057 train_loss= 119458.9141 train_acc= 0.9591 val_loss= 33311.3867 val_acc= 0.9208 test_loss= 33694.2344 test_acc= 0.9198 F1-score=0.9098 time= 1899.7556\n","58--loss_train\n","tensor(416.4065, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.964 0.9144 0.9135\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9657 0.914 0.914\n","Text: 0.8599 0.8572 0.8576\n","G+T: 0.9663 0.9268 0.9252\n","G+U+T: 0.963 0.9236 0.9227\n","Epoch: 0058 train_loss= 97752.1562 train_acc= 0.9630 val_loss= 30865.4941 val_acc= 0.9236 test_loss= 31303.9180 test_acc= 0.9227 F1-score=0.9136 time= 1951.0554\n","59--loss_train\n","tensor(417.9868, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9657 0.9186 0.918\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9636 0.9141 0.9141\n","Text: 0.859 0.8563 0.8573\n","G+T: 0.9631 0.9241 0.9237\n","G+U+T: 0.9577 0.9186 0.9187\n","Epoch: 0059 train_loss= 125660.3906 train_acc= 0.9577 val_loss= 34281.4102 val_acc= 0.9186 test_loss= 34591.5664 test_acc= 0.9187 F1-score=0.9082 time= 1922.5385\n","60--loss_train\n","tensor(436.0396, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9637 0.9142 0.9142\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9657 0.9136 0.9145\n","Text: 0.8593 0.8566 0.8574\n","G+T: 0.9648 0.9264 0.9245\n","G+U+T: 0.962 0.9242 0.9227\n","Epoch: 0060 train_loss= 101071.6562 train_acc= 0.9620 val_loss= 31140.9395 val_acc= 0.9242 test_loss= 31584.5508 test_acc= 0.9227 F1-score=0.9137 time= 1955.2758\n","61--loss_train\n","tensor(369.0378, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9658 0.9193 0.9187\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9638 0.9142 0.9144\n","Text: 0.8631 0.8596 0.8608\n","G+T: 0.9629 0.9249 0.9237\n","G+U+T: 0.9584 0.9204 0.9203\n","Epoch: 0061 train_loss= 123393.1562 train_acc= 0.9584 val_loss= 33737.8281 val_acc= 0.9204 test_loss= 34064.9531 test_acc= 0.9203 F1-score=0.9104 time= 1914.6796\n","62--loss_train\n","tensor(412.3719, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.964 0.9149 0.9139\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9656 0.9146 0.9149\n","Text: 0.8631 0.8615 0.8605\n","G+T: 0.964 0.9269 0.925\n","G+U+T: 0.9603 0.9236 0.9224\n","Epoch: 0062 train_loss= 106987.5000 train_acc= 0.9603 val_loss= 32162.5273 val_acc= 0.9236 test_loss= 32671.4121 test_acc= 0.9224 F1-score=0.9132 time= 1967.3624\n","63--loss_train\n","tensor(401.3624, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9656 0.9185 0.9183\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9639 0.9145 0.915\n","Text: 0.8625 0.8604 0.8602\n","G+T: 0.9634 0.9255 0.9245\n","G+U+T: 0.9592 0.9219 0.9213\n","Epoch: 0063 train_loss= 120291.4688 train_acc= 0.9592 val_loss= 32866.4062 val_acc= 0.9219 test_loss= 33320.0820 test_acc= 0.9213 F1-score=0.9116 time= 1924.0856\n","64--loss_train\n","tensor(378.8706, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9638 0.9148 0.9139\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9656 0.9146 0.915\n","Text: 0.8615 0.8585 0.8594\n","G+T: 0.9651 0.9273 0.9258\n","G+U+T: 0.9633 0.9263 0.9249\n","Epoch: 0064 train_loss= 97130.0547 train_acc= 0.9633 val_loss= 30243.1465 val_acc= 0.9263 test_loss= 30717.5918 test_acc= 0.9249 F1-score=0.9166 time= 1942.7043\n","65--loss_train\n","tensor(366.3964, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9657 0.919 0.9184\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9639 0.9146 0.9146\n","Text: 0.8639 0.8615 0.8619\n","G+T: 0.9613 0.926 0.9242\n","G+U+T: 0.9577 0.9233 0.9218\n","Epoch: 0065 train_loss= 125999.8594 train_acc= 0.9577 val_loss= 33321.1523 val_acc= 0.9233 test_loss= 34151.3203 test_acc= 0.9218 F1-score=0.9125 time= 1908.5416\n","66--loss_train\n","tensor(376.1826, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.964 0.9152 0.9144\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9656 0.9148 0.9155\n","Text: 0.8599 0.8567 0.8577\n","G+T: 0.9639 0.9264 0.9255\n","G+U+T: 0.9625 0.9251 0.9249\n","Epoch: 0066 train_loss= 99861.5703 train_acc= 0.9625 val_loss= 30736.4219 val_acc= 0.9251 test_loss= 30881.1191 test_acc= 0.9249 F1-score=0.9166 time= 1947.3854\n","67--loss_train\n","tensor(355.9398, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9658 0.9198 0.9187\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9639 0.9151 0.9147\n","Text: 0.8671 0.8635 0.8653\n","G+T: 0.9619 0.9257 0.9251\n","G+U+T: 0.9571 0.922 0.9208\n","Epoch: 0067 train_loss= 126734.9297 train_acc= 0.9571 val_loss= 33842.1797 val_acc= 0.9220 test_loss= 34289.3711 test_acc= 0.9208 F1-score=0.9110 time= 1910.3767\n","68--loss_train\n","tensor(332.3898, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9639 0.9147 0.9144\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9657 0.9144 0.9153\n","Text: 0.8653 0.8615 0.8628\n","G+T: 0.9639 0.9269 0.9259\n","G+U+T: 0.9601 0.9235 0.9226\n","Epoch: 0068 train_loss= 107187.8438 train_acc= 0.9601 val_loss= 32257.9883 val_acc= 0.9235 test_loss= 32339.6504 test_acc= 0.9226 F1-score=0.9135 time= 1942.0127\n","69--loss_train\n","tensor(383.2168, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9656 0.9197 0.9187\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.964 0.9154 0.9154\n","Text: 0.8673 0.8653 0.8646\n","G+T: 0.9594 0.9248 0.9242\n","G+U+T: 0.9537 0.9196 0.9188\n","Epoch: 0069 train_loss= 140319.0156 train_acc= 0.9537 val_loss= 35919.4180 val_acc= 0.9196 test_loss= 36225.5703 test_acc= 0.9188 F1-score=0.9086 time= 1918.3168\n","70--loss_train\n","tensor(353.0574, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9638 0.915 0.9156\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9657 0.9149 0.9159\n","Text: 0.8686 0.866 0.8663\n","G+T: 0.9637 0.9277 0.9271\n","G+U+T: 0.9607 0.9253 0.9246\n","Epoch: 0070 train_loss= 106143.0781 train_acc= 0.9607 val_loss= 31654.0977 val_acc= 0.9253 test_loss= 31761.1367 test_acc= 0.9246 F1-score=0.9160 time= 1976.7616\n","71--loss_train\n","tensor(359.3012, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9656 0.9197 0.9194\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9636 0.9154 0.9158\n","Text: 0.8705 0.8678 0.8689\n","G+T: 0.961 0.9262 0.9259\n","G+U+T: 0.9564 0.9215 0.9218\n","Epoch: 0071 train_loss= 130323.4141 train_acc= 0.9564 val_loss= 34172.0078 val_acc= 0.9215 test_loss= 34398.8047 test_acc= 0.9218 F1-score=0.9121 time= 1985.7088\n","72--loss_train\n","tensor(346.4832, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.964 0.915 0.9159\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9657 0.9154 0.916\n","Text: 0.8699 0.867 0.8675\n","G+T: 0.9634 0.9279 0.9276\n","G+U+T: 0.9604 0.9254 0.9251\n","Epoch: 0072 train_loss= 107321.4453 train_acc= 0.9604 val_loss= 31655.5547 val_acc= 0.9254 test_loss= 31723.2109 test_acc= 0.9251 F1-score=0.9165 time= 2177.5479\n","73--loss_train\n","tensor(404.8797, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9657 0.9205 0.9196\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9636 0.9154 0.9155\n","Text: 0.8713 0.868 0.8693\n","G+T: 0.9592 0.9257 0.9253\n","G+U+T: 0.9549 0.922 0.9218\n","Epoch: 0073 train_loss= 136081.6406 train_acc= 0.9549 val_loss= 34829.1016 val_acc= 0.9220 test_loss= 35183.2773 test_acc= 0.9218 F1-score=0.9124 time= 2156.4530\n","74--loss_train\n","tensor(378.1690, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.964 0.9158 0.9159\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9657 0.9159 0.9164\n","Text: 0.8708 0.8676 0.8685\n","G+T: 0.964 0.9281 0.9277\n","G+U+T: 0.9603 0.9242 0.9246\n","Epoch: 0074 train_loss= 108096.4922 train_acc= 0.9603 val_loss= 32142.0273 val_acc= 0.9242 test_loss= 32204.3848 test_acc= 0.9246 F1-score=0.9157 time= 2185.6035\n","75--loss_train\n","tensor(355.8005, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9656 0.9207 0.9202\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9637 0.9162 0.9155\n","Text: 0.8712 0.8682 0.8675\n","G+T: 0.9611 0.9281 0.9267\n","G+U+T: 0.9575 0.9249 0.9239\n","Epoch: 0075 train_loss= 126166.2969 train_acc= 0.9575 val_loss= 33199.3516 val_acc= 0.9249 test_loss= 33498.9883 test_acc= 0.9239 F1-score=0.9151 time= 2119.9610\n","76--loss_train\n","tensor(326.1177, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.964 0.9166 0.9172\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9657 0.9159 0.9166\n","Text: 0.8719 0.8679 0.8703\n","G+T: 0.962 0.9272 0.9272\n","G+U+T: 0.9594 0.9253 0.925\n","Epoch: 0076 train_loss= 112226.6719 train_acc= 0.9594 val_loss= 32408.4570 val_acc= 0.9253 test_loss= 32448.0879 test_acc= 0.9250 F1-score=0.9165 time= 2166.9438\n","77--loss_train\n","tensor(349.9963, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9658 0.9212 0.9212\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9636 0.9164 0.9162\n","Text: 0.8728 0.8694 0.8707\n","G+T: 0.9595 0.9263 0.9264\n","G+U+T: 0.9553 0.9234 0.9232\n","Epoch: 0077 train_loss= 134928.8281 train_acc= 0.9553 val_loss= 34489.7266 val_acc= 0.9234 test_loss= 34800.4570 test_acc= 0.9232 F1-score=0.9140 time= 2136.3027\n","78--loss_train\n","tensor(355.3583, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9639 0.9164 0.9175\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9658 0.9169 0.9171\n","Text: 0.8731 0.8692 0.8702\n","G+T: 0.9623 0.9278 0.9278\n","G+U+T: 0.9599 0.9263 0.9262\n","Epoch: 0078 train_loss= 110496.3125 train_acc= 0.9599 val_loss= 32059.8516 val_acc= 0.9263 test_loss= 32142.7383 test_acc= 0.9262 F1-score=0.9179 time= 2146.8228\n","79--loss_train\n","tensor(319.8990, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9655 0.9213 0.9209\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9638 0.9177 0.9172\n","Text: 0.8721 0.8677 0.8689\n","G+T: 0.9593 0.9266 0.9265\n","G+U+T: 0.9564 0.9248 0.9243\n","Epoch: 0079 train_loss= 131934.7969 train_acc= 0.9564 val_loss= 34029.6133 val_acc= 0.9248 test_loss= 34319.5312 test_acc= 0.9243 F1-score=0.9157 time= 2122.8190\n","80--loss_train\n","tensor(344.5404, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9639 0.9166 0.9169\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9657 0.9167 0.9172\n","Text: 0.8758 0.8715 0.8738\n","G+T: 0.9617 0.9282 0.9273\n","G+U+T: 0.9585 0.9258 0.9247\n","Epoch: 0080 train_loss= 116105.3125 train_acc= 0.9585 val_loss= 32856.1797 val_acc= 0.9258 test_loss= 33086.8750 test_acc= 0.9247 F1-score=0.9160 time= 2155.9705\n","81--loss_train\n","tensor(318.4665, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9657 0.9211 0.9214\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9637 0.9176 0.9174\n","Text: 0.875 0.871 0.8721\n","G+T: 0.9586 0.927 0.9268\n","G+U+T: 0.9552 0.9251 0.9242\n","Epoch: 0081 train_loss= 137687.6875 train_acc= 0.9552 val_loss= 34690.8359 val_acc= 0.9251 test_loss= 35049.5156 test_acc= 0.9242 F1-score=0.9155 time= 2117.9244\n","82--loss_train\n","tensor(320.3084, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9639 0.9171 0.9174\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9658 0.9172 0.9173\n","Text: 0.8743 0.8701 0.8718\n","G+T: 0.9616 0.928 0.9275\n","G+U+T: 0.9592 0.9264 0.9253\n","Epoch: 0082 train_loss= 114094.8906 train_acc= 0.9592 val_loss= 32605.7344 val_acc= 0.9264 test_loss= 32865.9141 test_acc= 0.9253 F1-score=0.9171 time= 2152.9044\n","83--loss_train\n","tensor(333.5402, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9655 0.9219 0.9219\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9636 0.9175 0.9176\n","Text: 0.8746 0.871 0.8715\n","G+T: 0.9552 0.9241 0.9239\n","G+U+T: 0.9502 0.9203 0.9195\n","Epoch: 0083 train_loss= 156455.9062 train_acc= 0.9502 val_loss= 38019.8711 val_acc= 0.9203 test_loss= 38052.3281 test_acc= 0.9195 F1-score=0.9094 time= 2117.3978\n","84--loss_train\n","tensor(300.2590, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.964 0.9177 0.9176\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9658 0.9166 0.9181\n","Text: 0.8768 0.8731 0.8741\n","G+T: 0.9614 0.9278 0.9283\n","G+U+T: 0.9584 0.9255 0.9253\n","Epoch: 0084 train_loss= 117631.7969 train_acc= 0.9584 val_loss= 33132.1797 val_acc= 0.9255 test_loss= 33267.9375 test_acc= 0.9253 F1-score=0.9168 time= 2149.0274\n","85--loss_train\n","tensor(364.6283, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9656 0.9216 0.922\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9637 0.9177 0.9184\n","Text: 0.8752 0.8716 0.8722\n","G+T: 0.9588 0.9271 0.927\n","G+U+T: 0.9562 0.9258 0.9255\n","Epoch: 0085 train_loss= 134008.7344 train_acc= 0.9562 val_loss= 34351.0078 val_acc= 0.9258 test_loss= 34435.7500 test_acc= 0.9255 F1-score=0.9171 time= 2120.9605\n","86--loss_train\n","tensor(321.2650, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.964 0.9185 0.918\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9657 0.9179 0.9186\n","Text: 0.8778 0.8733 0.875\n","G+T: 0.9613 0.9279 0.9278\n","G+U+T: 0.9585 0.9266 0.926\n","Epoch: 0086 train_loss= 117703.2266 train_acc= 0.9585 val_loss= 33129.1719 val_acc= 0.9266 test_loss= 33042.4688 test_acc= 0.9260 F1-score=0.9177 time= 2113.0981\n","87--loss_train\n","tensor(317.9062, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9655 0.9219 0.9219\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9635 0.918 0.9183\n","Text: 0.8781 0.8736 0.8754\n","G+T: 0.9571 0.9276 0.9268\n","G+U+T: 0.9533 0.9244 0.9238\n","Epoch: 0087 train_loss= 146321.2656 train_acc= 0.9533 val_loss= 36158.4102 val_acc= 0.9244 test_loss= 36233.1602 test_acc= 0.9238 F1-score=0.9149 time= 1920.4477\n","88--loss_train\n","tensor(312.2029, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9643 0.9179 0.9188\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9658 0.9176 0.9183\n","Text: 0.8791 0.8747 0.8762\n","G+T: 0.9609 0.9285 0.9282\n","G+U+T: 0.9572 0.9258 0.9256\n","Epoch: 0088 train_loss= 121825.7734 train_acc= 0.9572 val_loss= 33829.7266 val_acc= 0.9258 test_loss= 33889.6836 test_acc= 0.9256 F1-score=0.9170 time= 1953.6066\n","89--loss_train\n","tensor(320.9595, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9655 0.9216 0.922\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9636 0.9175 0.9179\n","Text: 0.8806 0.8768 0.8787\n","G+T: 0.9574 0.9278 0.9274\n","G+U+T: 0.9537 0.9241 0.9243\n","Epoch: 0089 train_loss= 144968.1406 train_acc= 0.9537 val_loss= 35983.9102 val_acc= 0.9241 test_loss= 36060.5312 test_acc= 0.9243 F1-score=0.9155 time= 1904.2367\n","90--loss_train\n","tensor(353.3421, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9639 0.9173 0.9183\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9656 0.9174 0.9175\n","Text: 0.8813 0.8785 0.8792\n","G+T: 0.9595 0.9284 0.9286\n","G+U+T: 0.9566 0.9266 0.9261\n","Epoch: 0090 train_loss= 127242.7891 train_acc= 0.9566 val_loss= 34449.7695 val_acc= 0.9266 test_loss= 34634.5547 test_acc= 0.9261 F1-score=0.9178 time= 1940.5989\n","91--loss_train\n","tensor(342.2638, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9655 0.9218 0.9228\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9633 0.9168 0.9177\n","Text: 0.8791 0.875 0.8777\n","G+T: 0.9554 0.9266 0.9259\n","G+U+T: 0.9503 0.9219 0.9215\n","Epoch: 0091 train_loss= 156099.0938 train_acc= 0.9503 val_loss= 37733.5742 val_acc= 0.9219 test_loss= 37839.1445 test_acc= 0.9215 F1-score=0.9119 time= 1933.3077\n","92--loss_train\n","tensor(301.7803, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9638 0.9178 0.9185\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9659 0.9181 0.9184\n","Text: 0.8808 0.8774 0.8793\n","G+T: 0.9585 0.9284 0.9272\n","G+U+T: 0.9548 0.9247 0.9245\n","Epoch: 0092 train_loss= 133571.8438 train_acc= 0.9548 val_loss= 35382.2305 val_acc= 0.9247 test_loss= 35552.3789 test_acc= 0.9245 F1-score=0.9156 time= 1947.9824\n","93--loss_train\n","tensor(326.6597, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9655 0.9225 0.9232\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9634 0.9182 0.9178\n","Text: 0.8814 0.877 0.8791\n","G+T: 0.9571 0.9276 0.9281\n","G+U+T: 0.9533 0.9244 0.9249\n","Epoch: 0093 train_loss= 148993.1719 train_acc= 0.9533 val_loss= 36386.3906 val_acc= 0.9244 test_loss= 36365.2383 test_acc= 0.9249 F1-score=0.9160 time= 1923.2167\n","94--loss_train\n","tensor(275.7827, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.964 0.9187 0.9193\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9658 0.9184 0.9183\n","Text: 0.8809 0.8773 0.8791\n","G+T: 0.9587 0.9286 0.9278\n","G+U+T: 0.9556 0.9257 0.9256\n","Epoch: 0094 train_loss= 130759.0391 train_acc= 0.9556 val_loss= 34995.7188 val_acc= 0.9257 test_loss= 35091.5703 test_acc= 0.9256 F1-score=0.9171 time= 1944.7521\n","95--loss_train\n","tensor(343.5419, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9655 0.9226 0.9235\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9635 0.9181 0.9181\n","Text: 0.8799 0.8766 0.8776\n","G+T: 0.9576 0.9291 0.9286\n","G+U+T: 0.9546 0.9263 0.9263\n","Epoch: 0095 train_loss= 142875.1719 train_acc= 0.9546 val_loss= 35362.2969 val_acc= 0.9263 test_loss= 35532.0781 test_acc= 0.9263 F1-score=0.9180 time= 1919.8427\n","96--loss_train\n","tensor(334.5594, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9639 0.9185 0.9188\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9658 0.9183 0.9183\n","Text: 0.8832 0.8796 0.8809\n","G+T: 0.958 0.9289 0.928\n","G+U+T: 0.955 0.9263 0.9253\n","Epoch: 0096 train_loss= 134165.0312 train_acc= 0.9550 val_loss= 35340.1719 val_acc= 0.9263 test_loss= 35454.3086 test_acc= 0.9253 F1-score=0.9168 time= 1943.3470\n","97--loss_train\n","tensor(333.9886, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9656 0.9229 0.9233\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9632 0.9182 0.918\n","Text: 0.8819 0.8779 0.8797\n","G+T: 0.9563 0.927 0.9276\n","G+U+T: 0.9532 0.9251 0.9257\n","Epoch: 0097 train_loss= 150033.1406 train_acc= 0.9532 val_loss= 36591.1992 val_acc= 0.9251 test_loss= 36401.2891 test_acc= 0.9257 F1-score=0.9172 time= 1901.2383\n","98--loss_train\n","tensor(310.9996, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9639 0.9186 0.919\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9657 0.918 0.9179\n","Text: 0.8812 0.8775 0.8788\n","G+T: 0.959 0.9285 0.9292\n","G+U+T: 0.9565 0.9272 0.9275\n","Epoch: 0098 train_loss= 129056.8281 train_acc= 0.9565 val_loss= 34562.7969 val_acc= 0.9272 test_loss= 34286.3516 test_acc= 0.9275 F1-score=0.9195 time= 1934.9902\n","99--loss_train\n","tensor(318.6295, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9657 0.9231 0.9233\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9632 0.9176 0.918\n","Text: 0.8839 0.8803 0.8819\n","G+T: 0.9555 0.928 0.9276\n","G+U+T: 0.9523 0.9252 0.9245\n","Epoch: 0099 train_loss= 155791.8594 train_acc= 0.9523 val_loss= 37217.6289 val_acc= 0.9252 test_loss= 37451.0000 test_acc= 0.9245 F1-score=0.9157 time= 1902.2366\n","100--loss_train\n","tensor(306.0407, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.964 0.919 0.9194\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9657 0.9179 0.9184\n","Text: 0.8799 0.8762 0.8782\n","G+T: 0.9578 0.9287 0.928\n","G+U+T: 0.9559 0.9275 0.9274\n","Epoch: 0100 train_loss= 131902.2031 train_acc= 0.9559 val_loss= 34540.0117 val_acc= 0.9275 test_loss= 34813.1719 test_acc= 0.9274 F1-score=0.9195 time= 1934.3581\n","101--loss_train\n","tensor(278.9492, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9656 0.9232 0.9233\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9632 0.9174 0.9178\n","Text: 0.8835 0.8798 0.8814\n","G+T: 0.9543 0.927 0.9277\n","G+U+T: 0.9512 0.9247 0.925\n","Epoch: 0101 train_loss= 162332.8594 train_acc= 0.9512 val_loss= 38007.1875 val_acc= 0.9247 test_loss= 38078.2812 test_acc= 0.9250 F1-score=0.9163 time= 1912.4043\n","102--loss_train\n","tensor(313.7120, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.964 0.9183 0.9197\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9658 0.9182 0.9191\n","Text: 0.8849 0.881 0.8826\n","G+T: 0.9579 0.9285 0.9284\n","G+U+T: 0.9545 0.9258 0.9256\n","Epoch: 0102 train_loss= 138959.4688 train_acc= 0.9545 val_loss= 36118.8750 val_acc= 0.9258 test_loss= 35932.5547 test_acc= 0.9256 F1-score=0.9170 time= 1940.3204\n","103--loss_train\n","tensor(274.8398, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9655 0.9231 0.9234\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9635 0.9178 0.9178\n","Text: 0.8845 0.8801 0.8817\n","G+T: 0.9542 0.9265 0.9269\n","G+U+T: 0.9499 0.9222 0.9225\n","Epoch: 0103 train_loss= 166333.9844 train_acc= 0.9499 val_loss= 38970.1289 val_acc= 0.9222 test_loss= 38838.1953 test_acc= 0.9225 F1-score=0.9130 time= 1899.8335\n","104--loss_train\n","tensor(329.2865, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9638 0.9184 0.9186\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9658 0.9181 0.9183\n","Text: 0.8811 0.8777 0.8777\n","G+T: 0.9577 0.929 0.9287\n","G+U+T: 0.9563 0.9278 0.9279\n","Epoch: 0104 train_loss= 132896.1250 train_acc= 0.9563 val_loss= 34717.1055 val_acc= 0.9278 test_loss= 34669.3984 test_acc= 0.9279 F1-score=0.9202 time= 1937.5549\n","105--loss_train\n","tensor(299.3404, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9656 0.9229 0.9235\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9633 0.9173 0.9176\n","Text: 0.8859 0.883 0.8832\n","G+T: 0.9537 0.9266 0.927\n","G+U+T: 0.9499 0.9232 0.9236\n","Epoch: 0105 train_loss= 171204.2969 train_acc= 0.9499 val_loss= 39541.1836 val_acc= 0.9232 test_loss= 39394.8945 test_acc= 0.9236 F1-score=0.9145 time= 1907.9808\n","106--loss_train\n","tensor(305.2451, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9641 0.919 0.9195\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9657 0.918 0.9179\n","Text: 0.8835 0.8799 0.8812\n","G+T: 0.9575 0.9288 0.9284\n","G+U+T: 0.9553 0.9269 0.9267\n","Epoch: 0106 train_loss= 137618.7969 train_acc= 0.9553 val_loss= 35537.9961 val_acc= 0.9269 test_loss= 35507.5195 test_acc= 0.9267 F1-score=0.9186 time= 1945.5348\n","107--loss_train\n","tensor(368.1307, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9657 0.9238 0.9229\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9636 0.9174 0.9173\n","Text: 0.8865 0.8828 0.8832\n","G+T: 0.9549 0.928 0.928\n","G+U+T: 0.9512 0.9245 0.9245\n","Epoch: 0107 train_loss= 163117.8594 train_acc= 0.9512 val_loss= 38370.7539 val_acc= 0.9245 test_loss= 38302.9922 test_acc= 0.9245 F1-score=0.9156 time= 1902.9876\n","108--loss_train\n","tensor(298.8171, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9639 0.9191 0.9191\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9658 0.9184 0.9181\n","Text: 0.8858 0.8828 0.8827\n","G+T: 0.9568 0.9289 0.9285\n","G+U+T: 0.9543 0.9271 0.9265\n","Epoch: 0108 train_loss= 142660.2188 train_acc= 0.9543 val_loss= 36104.6055 val_acc= 0.9271 test_loss= 36194.0234 test_acc= 0.9265 F1-score=0.9184 time= 1937.6846\n","109--loss_train\n","tensor(306.8969, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9657 0.9234 0.9237\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9631 0.9174 0.9179\n","Text: 0.8842 0.8799 0.8822\n","G+T: 0.9547 0.9277 0.9275\n","G+U+T: 0.9514 0.9249 0.9253\n","Epoch: 0109 train_loss= 160698.6562 train_acc= 0.9514 val_loss= 37954.1133 val_acc= 0.9249 test_loss= 37851.4258 test_acc= 0.9253 F1-score=0.9169 time= 1915.5406\n","110--loss_train\n","tensor(299.9603, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.964 0.9196 0.9196\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9659 0.9181 0.9186\n","Text: 0.8859 0.8827 0.8832\n","G+T: 0.9558 0.9287 0.9276\n","G+U+T: 0.9539 0.9277 0.9258\n","Epoch: 0110 train_loss= 146567.8125 train_acc= 0.9539 val_loss= 36232.0664 val_acc= 0.9277 test_loss= 36772.5820 test_acc= 0.9258 F1-score=0.9178 time= 1950.4266\n","111--loss_train\n","tensor(300.0432, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9655 0.9241 0.9231\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9635 0.9172 0.9173\n","Text: 0.884 0.881 0.8815\n","G+T: 0.9544 0.9279 0.9276\n","G+U+T: 0.9524 0.9267 0.9259\n","Epoch: 0111 train_loss= 158913.9375 train_acc= 0.9524 val_loss= 37297.3398 val_acc= 0.9267 test_loss= 37666.9297 test_acc= 0.9259 F1-score=0.9179 time= 1901.1314\n","112--loss_train\n","tensor(341.4274, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9641 0.9202 0.9198\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9658 0.9182 0.918\n","Text: 0.8852 0.882 0.8837\n","G+T: 0.9564 0.9296 0.9288\n","G+U+T: 0.9548 0.9284 0.9279\n","Epoch: 0112 train_loss= 142751.3906 train_acc= 0.9548 val_loss= 35807.6133 val_acc= 0.9284 test_loss= 36309.9062 test_acc= 0.9279 F1-score=0.9201 time= 1945.9370\n","113--loss_train\n","tensor(328.2486, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.9657 0.9243 0.924\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9631 0.9176 0.9173\n","Text: 0.8872 0.8845 0.8842\n","G+T: 0.9542 0.9283 0.9278\n","G+U+T: 0.951 0.9252 0.9245\n","Epoch: 0113 train_loss= 167197.1875 train_acc= 0.9510 val_loss= 38643.5078 val_acc= 0.9252 test_loss= 38986.6211 test_acc= 0.9245 F1-score=0.9158 time= 1899.5635\n","114--loss_train\n","tensor(292.7365, device='cuda:0', grad_fn=<AddBackward0>)\n","Graph: 0.964 0.9203 0.9198\n","User: 0.6444 0.6433 0.6447\n","G+U: 0.9657 0.9178 0.9181\n","Text: 0.888 0.885 0.8859\n","G+T: 0.9557 0.9294 0.9285\n","G+U+T: 0.9532 0.9266 0.9261\n","Epoch: 0114 train_loss= 149517.3750 train_acc= 0.9532 val_loss= 37122.9609 val_acc= 0.9266 test_loss= 37250.6562 test_acc= 0.9261 F1-score=0.9178 time= 1941.7847\n","Too long time not up\n","best_result:\n","(112, 142751.390625, 35807.61328125, 36309.90625, [[0.9641045206946838, 0.9201697871431622, 0.9197501201345507], [0.6444044987814225, 0.6432868228091407, 0.6447042910281737], [0.965759694949605, 0.9182209724496334, 0.9179881467243313], [0.8851611625819383, 0.881967679931658, 0.8836652606474807], [0.9563581272059257, 0.9296468996938848, 0.9288358517094701], [0.9547685815000907, 0.9283921833843525, 0.9278836741595031]])\n"]}],"source":["import sys\n","sys.path.append(r\"/home/kayzhou/zhangyue/text/text_UNION/test_GCN_LSTM\")\n","from model import GraphConvolution, GCNModel\n","from utils import *\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import pickle as pkl\n","import os\n","import sys\n","import time\n","import argparse\n","from sklearn.metrics import f1_score\n","#os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n","class Trainer:\n","    def __init__(self, args):\n","\n","        print(args)\n","        \n","        # Define Parameters\n","        self.DATASET = args['dataset']\n","        self.NB_EPOCH = args['epochs']\n","        self.LR = args['learnrate']\n","        self.L2 = args['l2norm']\n","        self.HIDDEN = args['hidden']\n","        self.BASES = args['bases']\n","        self.use_cuda = True #原本为True\n","        self.TEXT_MODEL = args['text_model']\n","        self.SUPERVISE_FLAG = args['supervise_flag']   \n","        self.PRED_TYPE = args['pred_type']   \n","        self.USE_BIAS = True\n","        self.MODEL_NAME = '%s_%s_%s' % (self.DATASET, self.TEXT_MODEL, self.SUPERVISE_FLAG) # '_64hlstm30_withtext'\n","        self.num_features = 16\n","        self.log_step = 1\n","        \n","\n","        # Load Data\n","        #去掉文件名返回目录\n","        dirname = \"/home/kayzhou/zhangyue/text/data_GCN/data_processed/\"\n","        #utils load_data\n","        raw_data, data = load_data(\n","                args, dirname, self.use_cuda, self.SUPERVISE_FLAG)\n","        #A = raw_data['A']\n","        y = raw_data['y']\n","        #Series.to_dense()函数已返回给定系列对象的密集表示形式。\n","        #它分配了内存以存储系列中的缺失值。当缺少大量数据时，密集表示对内存的效率不高。\n","        y = np.array(y)\n","        self.labels = y\n","\n","        self.idx_train = data['idx_train'] \n","        self.idx_valid = data['idx_valid']  \n","        self.idx_test= data['idx_test'] \n","        self.idx_train_set = data['idx_train_set'] \n","        self.idx_test_set = data['idx_test_set'] \n","        self.inputs = data['inputs']\n","        self.labels_train = data['labels_train'] \n","        self.labels_valid = data['labels_valid']  \n","        self.labels_test = data['labels_test']  \n","        self.num_nodes = data['num_nodes']  \n","        self.num_docs = data['num_docs']  \n","        self.num_non_docs= data['num_non_docs']\n","        self.node2adj = data['node2adj']\n","        self.support = data['support']\n","        self.idx_train_pre = (np.array(self.idx_train)+self.num_non_docs).tolist()\n","        self.idx_valid_pre = (np.array(self.idx_valid)+self.num_non_docs).tolist()\n","        self.idx_test_pre = (np.array(self.idx_test)+self.num_non_docs).tolist()\n","        self.text_batch_size = 1000\n","     \n","\n","\n","        print('Data loaded successfully!')\n","\n","        # Compile Model\n","        #定义模型的基本参数\n","        \n","        self.model = GCNModel(data, self.num_features, self.num_nodes, self.HIDDEN, self.support, self.BASES, 2, \n","            text_model=self.TEXT_MODEL, bias_feature=self.USE_BIAS)\n","        if (self.use_cuda):\n","            self.model = self.model.cuda()\n","            #self.model = self.model\n","\n","        parameters = [p for p in list(self.model.parameters())\n","            if p.requires_grad]\n","        # for p in parameters:\n","        #     print(p.size())\n","        self.optimizer = optim.Adam(parameters,\n","                            lr=self.LR, weight_decay=self.L2)\n","\n","        #lstm为sum\n","        self.cross_entropy_loss = nn.CrossEntropyLoss(reduction='sum')\n","\n","    \n","    def _train(self):\n","        # Fit Model\n","        best_acc, best_test_acc = 0, 0\n","        best_loss = 10000000\n","        best_loss_train = 1000000\n","        best_epoch = 0\n","        \n","        loss_list = []\n","        train_acc_list = []\n","        dev_acc_list = []\n","        test_acc_list = []\n","        \n","        for epoch in range(1, self.NB_EPOCH + 1):\n","            # Log wall-clock time\n","            t = time.time()\n","\n","            self.model.zero_grad()\n","\n","            # Single training iteration\n","            embeds_0 = self.inputs[0] \n","            embeds_1 = self.model.gc1([embeds_0] + self.inputs[1:])\n","            embeds_2 = self.model.gc2([embeds_1] + self.inputs[1:])\n","            embeds_final = embeds_2\n","            scores = self.model.clf_bias(embeds_2)\n","            loss_train = self.cross_entropy_loss(scores[self.idx_train_pre], self.labels_train) \n","\n","            #调整loss的系数\n","            #loss_train *= 10\n","            loss_train.backward()\n","            self.optimizer.step()\n","            \n","            #猜测doc节点的编号是在最后，所以利用以下公式\n","            #np.random.permutation对range()之间的序列进行随机排序\n","            ##self.num_non_docs=num_nodes - num_docs\n","            text_idx_perm = np.random.permutation(range(self.num_non_docs, self.num_nodes))\n","            #如果预测类型是text或者all则运行\n","            #如果TEXT_MODEL不是HLSTM且预测类型是text或者all只循环一次\n","\n","            for start in range(0, self.num_docs, self.text_batch_size):\n","                if (self.PRED_TYPE not in ['text', 'all']):\n","                    break\n","                self.model.zero_grad()\n","                end = start + self.text_batch_size\n","                if (end > self.num_docs):\n","                    end = self.num_docs\n","                doc_idx_list_raw = text_idx_perm[start:end]\n","                #inputs 在utils可找到\n","                embeds_0 = self.inputs[0] # model.input_layer()\n","                #[1，2]+[2，3]=[1,2,2,3]\n","                embeds_1 = self.model.gc1([embeds_0] + self.inputs[1:])\n","                embeds_2 = self.model.gc2([embeds_1] + self.inputs[1:])\n","                embeds_final = embeds_2\n","                \n","                doctext_idx_list, docnode_pos_idx, docnode_neg_idx, doctext_flag = [], [], [], []\n","                for tidx, doctext_idx in enumerate(doc_idx_list_raw):\n","                    doctext_idx_list.append(doctext_idx)\n","                    \n","                    docnode_pos_idx.append(doctext_idx) \n","                    #pos集合增加1个neg集合增加5个\n","                    docnode_neg_idx.append(np.random.randint(self.num_non_docs, self.num_nodes, size=(5)))\n","                    \n","                    if (doctext_idx in self.idx_train_set):\n","                        doctext_flag.append(tidx)\n","                        \n","                docnode_pos_idx = np.array(docnode_pos_idx).reshape(-1, 1)\n","                docnode_neg_idx = np.array(docnode_neg_idx)\n","                docnode_idx_list = np.concatenate((docnode_pos_idx, docnode_neg_idx), axis=1)\n","\n","                #doctext_idx_list = torch.LongTensor(doctext_idx_list)\n","                doctext_idx_list = torch.LongTensor(doctext_idx_list).cuda()\n","                batch_input = self.model.input_layer.get_doc_embed(doctext_idx_list-self.num_non_docs)\n","                docnode_idx_list = torch.LongTensor(docnode_idx_list).cuda()\n","                #docnode_idx_list = torch.cuda.LongTensor(docnode_idx_list)\n","                #docnode_idx_list = torch.LongTensor(docnode_idx_list)\n","                #取出docnode索引所对应的embeds_final的维度1，再将其维度进行重构\n","                batch_target = embeds_final.index_select(0, docnode_idx_list.view(-1)).view(-1, 6, self.num_features)\n","                \n","                #-1表示自定计算改维度数值\n","                #batch_input表示doc节点嵌入\n","                #torch.bmm矩阵乘法\n","                batch_scores = torch.bmm(batch_target, \n","                    batch_input.view(-1, self.num_features, 1)).squeeze()\n","                batch_labels = torch.LongTensor([0] * len(doctext_idx_list)).cuda()\n","                #batch_labels均设置为0\n","                #batch_labels = torch.LongTensor([0] * len(doctext_idx_list))\n","                loss_text_node = self.cross_entropy_loss(batch_scores, batch_labels)\n","\n","                if (len(doctext_flag) > 0):\n","                    #self.model.clf_bias为一个线性层\n","                    scores_text = self.model.clf_bias(batch_input)\n","                    loss_text = self.cross_entropy_loss(scores_text[doctext_flag], \n","                                                        torch.LongTensor(self.labels[docnode_pos_idx-self.num_non_docs][doctext_flag]).cuda().view(-1))\n","                    # loss_text = self.cross_entropy_loss(scores_text[doctext_flag], \n","                    #                                     torch.LongTensor(self.labels[docnode_pos_idx-self.num_non_docs][doctext_flag]).view(-1))\n","                            #torch.LongTensor(self.labels[docnode_pos_idx][doctext_flag])..view(-1))\n","                            \n","                    \n","                else: \n","                    loss_text = torch.tensor(0).cuda()\n","                    #loss_text = torch.tensor(0)\n","                #HLSTM模型一个epoch比别的text模型多反向传播\n","                loss_train = loss_text_node + loss_text\n","                loss_train.backward()\n","                self.optimizer.step()\n","\n","\n","\n","            #上一个if结束\n","\n","\n","            loss_list.append(loss_train)\n","            print(str(epoch)+\"--loss_train\")\n","            print(loss_train)\n","            # Evaluate model and save the best one based on performance on validataion set\n","            if epoch % self.log_step == 0:\n","\n","                preds_test,labels_test,loss_train_val, loss_valid_val, loss_test_val,train_acc_sel, valid_acc_sel, test_acc_sel, preds_sel, result_table = self._evaluate()\n","                \n","                train_acc_list.append(train_acc_sel)\n","                dev_acc_list.append(valid_acc_sel)\n","                test_acc_list.append(test_acc_sel)\n","\n","                f1 = f1_score(preds_test.cpu(), labels_test.cpu(),average=\"macro\")\n","                print(\"Epoch: {:04d}\".format(epoch),\n","                    \"train_loss= {:.4f}\".format(loss_train_val),\n","                    \"train_acc= {:.4f}\".format(train_acc_sel),\n","                    \"val_loss= {:.4f}\".format(loss_valid_val),\n","                    \"val_acc= {:.4f}\".format(valid_acc_sel),\n","                    \"test_loss= {:.4f}\".format(loss_test_val),\n","                    \"test_acc= {:.4f}\".format(test_acc_sel),\n","                    \"F1-score={:.4f}\".format(f1),\n","                    \"time= {:.4f}\".format(time.time() - t))\n","                \n","                #最好的结果仍旧是准确率最高的结果\n","                if (test_acc_sel > best_acc):\n","                    best_acc = test_acc_sel\n","                    best_loss = loss_test_val\n","                    best_result = (epoch, loss_train_val, loss_valid_val, loss_test_val, \n","                        result_table)\n","                    best_yuce_tag=preds_test\n","                    torch.save(self.model.state_dict(), '/home/kayzhou/zhangyue/text/text_UNION/test_GCN_LSTM/saved_models/%s' % self.MODEL_NAME)\n","                #用于判断是否结束训练\n","\n","            else:\n","                print(\"Epoch: {:04d}\".format(epoch),\n","                    \"time= {:.4f}\".format(time.time() - t))\n","                \n","            \n","\n","            if loss_train< best_loss_train:\n","              best_loss_train = loss_train\n","              best_epoch = epoch\n","\n","            if epoch-best_epoch > 10:\n","              print(\"Too long time not up\")\n","              break\n","          \n","\n","        print(\"best_result:\")\n","        print(best_result)\n","            \n","            \n","            \n","            \n","\n","        #print(best_result)\n","        fout = open('/home/kayzhou/zhangyue/text/text_UNION/test_GCN_LSTM/logs/result_%s.txt' % self.DATASET, 'a')\n","        fout.write(str(best_result) + '\\n')\n","        fout.close()\n","        return best_yuce_tag,labels_test,loss_list, train_acc_list, dev_acc_list, test_acc_list\n","\n","\n","\n","\n","    def _evaluate(self, verbose=True):\n","        \n","        # Predict on full dataset\n","        embeds_0 = self.inputs[0] # model.input_layer()\n","        embeds_1 = self.model.gc1([embeds_0] + self.inputs[1:])\n","        embeds_2 = self.model.gc2([embeds_1] + self.inputs[1:])\n","        scores = self.model.clf_bias(embeds_2)\n","        preds = torch.argmax(scores, dim=1)\n","        loss_train = self.cross_entropy_loss(scores[self.idx_train_pre], self.labels_train)\n","        loss_valid = self.cross_entropy_loss(scores[self.idx_valid_pre], self.labels_valid)\n","        loss_test = self.cross_entropy_loss(scores[self.idx_test_pre], self.labels_test)\n","        correct_train = torch.sum(preds[self.idx_train_pre] == self.labels_train)\n","        correct_valid = torch.sum(preds[self.idx_valid_pre] == self.labels_valid)\n","        correct_test = torch.sum(preds[self.idx_test_pre] == self.labels_test)\n","        \n","        #计算准确率\n","        train_acc_net = correct_train.item()/self.labels_train.size(0)\n","        valid_acc_net = correct_valid.item()/self.labels_valid.size(0)\n","        test_acc_net = correct_test.item()/self.labels_test.size(0)\n","        \n","        if verbose:\n","            #整张图上的准确率\n","            print('Graph:', round(train_acc_net,4), round(valid_acc_net,4),round(test_acc_net,4))\n","\n","\n","        scores_shareu = []\n","        #scores_value = scores.data.numpy()\n","        scores_value = scores.data.cpu().numpy()\n","        for node in range(self.num_nodes):\n","            scores_t = np.zeros(2) \n","            \n","            #self.node2adj为doc节点 to share用户节点\n","            if (node not in self.node2adj):\n","                scores_shareu.append(scores_t)\n","                continue\n","            \n","            #分享文档的用户集合\n","            adj = list(self.node2adj[node])\n","            \n","            adj_coef = [1/len(adj)] * len(adj)\n","            \n","            #根据加权分享该文档的用户节点的预测得到文档预测\n","            for user, coef in zip(adj, adj_coef):\n","                scores_t += coef * scores_value[user] \n","            scores_shareu.append(scores_t) \n","            \n","        #scores_shareu = torch.FloatTensor(np.array(scores_shareu))\n","        scores_shareu = torch.FloatTensor(np.array(scores_shareu)).cuda()\n","        preds_shareu = torch.argmax(scores_shareu, dim=1)\n","        correct_train_shareu = torch.sum(preds_shareu[self.idx_train_pre] == self.labels_train)\n","        correct_valid_shareu = torch.sum(preds_shareu[self.idx_valid_pre] == self.labels_valid)\n","        correct_test_shareu = torch.sum(preds_shareu[self.idx_test_pre] == self.labels_test)\n","        train_acc_shareu = correct_train_shareu.item()/self.labels_train.size(0)\n","        valid_acc_shareu = correct_valid_shareu.item()/self.labels_valid.size(0)\n","        test_acc_shareu = correct_test_shareu.item()/self.labels_test.size(0)\n","        if verbose:\n","            print('User:', round(train_acc_shareu,4), round(valid_acc_shareu,4), round(test_acc_shareu,4))\n","\n","        #结合图预测的文档分类和用户预测的文档节点分类\n","        scores_shareu += scores\n","        preds_netshareu = torch.argmax(scores_shareu, dim=1)\n","        correct_train_shareu = torch.sum(preds_netshareu[self.idx_train_pre] == self.labels_train)\n","        correct_valid_shareu = torch.sum(preds_netshareu[self.idx_valid_pre] == self.labels_valid)\n","        correct_test_shareu = torch.sum(preds_netshareu[self.idx_test_pre] == self.labels_test)\n","        train_acc_netshareu = correct_train_shareu.item()/self.labels_train.size(0)\n","        valid_acc_netshareu = correct_valid_shareu.item()/self.labels_valid.size(0)\n","        test_acc_netshareu = correct_test_shareu.item()/self.labels_test.size(0)\n","        if verbose:\n","            print('G+U:', round(train_acc_netshareu,4), round(valid_acc_netshareu,4), round(test_acc_netshareu,4))\n","        \n","        #-----------------\n","        text_idx_perm = [i for i in range(self.num_docs)]\n","        scores_text = []\n","        for start in range(0,self. num_docs, self.text_batch_size):\n","            self.model.zero_grad()\n","            end = start + self.text_batch_size\n","            if (end > self.num_docs):\n","                end = self.num_docs\n","            doc_idx_list_raw = text_idx_perm[start:end]\n","            #doctext_idx_list = torch.LongTensor(doc_idx_list_raw)\n","            doctext_idx_list = torch.LongTensor(doc_idx_list_raw).cuda()\n","            batch_input = self.model.input_layer.get_doc_embed(doctext_idx_list)\n","                # torch.mm(model.gc2.W[0])\n","            scores_text.extend(list(self.model.clf_bias(batch_input).data.cpu().numpy()))\n","            #scores_text.extend(list(self.model.clf_bias(batch_input).data.numpy()))\n","            #！！！！！！！！！！！！！！！！！！！！！！！修改\n","            #scores_text.extend(list(batch_input).cpu().numpy())\n","        #scores_text = torch.FloatTensor(scores_text)\n","        \n","        scores_text = np.array(scores_text)\n","        scores_text = torch.FloatTensor(scores_text).cuda()\n","        #scores_text = torch.FloatTensor(scores_text)\n","        preds_text = torch.argmax(scores_text, dim=1)\n","        # print(idx_train-num_non_docs)\n","        # print(preds_shareu[idx_train-num_non_docs])\n","        # exit()\n","        correct_train = torch.sum(preds_text[self.idx_train] == self.labels_train)\n","        correct_valid = torch.sum(preds_text[self.idx_valid] == self.labels_valid)\n","        correct_test = torch.sum(preds_text[self.idx_test] == self.labels_test)\n","        train_acc_text = correct_train.item()/self.labels_train.size(0)\n","        valid_acc_text = correct_valid.item()/self.labels_valid.size(0)\n","        test_acc_text = correct_test.item()/self.labels_test.size(0)\n","\n","        loss_text_train = self.cross_entropy_loss(scores_text[self.idx_train], self.labels_train)\n","        loss_text_valid = self.cross_entropy_loss(scores_text[self.idx_valid], self.labels_valid)\n","        loss_text_test = self.cross_entropy_loss(scores_text[self.idx_test], self.labels_test)\n","\n","        if verbose:\n","            print('Text:', round(train_acc_text,4), round(valid_acc_text,4), round(test_acc_text,4))\n","\n","\n","\n","        \n","        #scores_g_t = torch.cat((scores[self.num_non_docs:],scores_text),dim=1)\n","        scores[self.num_non_docs:] += scores_text\n","        preds_nettext = torch.argmax(scores, dim=1)\n","        correct_train = torch.sum(preds_nettext[self.idx_train_pre] == self.labels_train)\n","        correct_valid = torch.sum(preds_nettext[self.idx_valid_pre] == self.labels_valid)\n","        correct_test = torch.sum(preds_nettext[self.idx_test_pre] == self.labels_test)\n","        train_acc_nettext = correct_train.item()/self.labels_train.size(0)\n","        valid_acc_nettext = correct_valid.item()/self.labels_valid.size(0)\n","        test_acc_nettext = correct_test.item()/self.labels_test.size(0)\n","        if verbose:\n","            print('G+T:', round(train_acc_nettext,4), round(valid_acc_nettext,4), round(test_acc_nettext,4))\n","\n","        \n","        #scores_shareu[self.num_non_docs:] = torch.cat((scores_shareu[self.num_non_docs:],scores_text),dim=1)\n","        scores_shareu[self.num_non_docs:] += scores_text\n","        preds_all = torch.argmax(scores_shareu, dim=1)\n","        correct_train = torch.sum(preds_all[self.idx_train_pre] == self.labels_train)\n","        correct_valid = torch.sum(preds_all[self.idx_valid_pre] == self.labels_valid)\n","        correct_test = torch.sum(preds_all[self.idx_test_pre] == self.labels_test)\n","        train_acc_all = correct_train.item()/self.labels_train.size(0)\n","        valid_acc_all = correct_valid.item()/self.labels_valid.size(0)\n","        test_acc_all = correct_test.item()/self.labels_test.size(0)\n","\n","        loss_all_train = self.cross_entropy_loss(scores_shareu[self.idx_train_pre], self.labels_train)\n","        loss_all_valid = self.cross_entropy_loss(scores_shareu[self.idx_valid_pre], self.labels_valid)\n","        loss_all_test = self.cross_entropy_loss(scores_shareu[self.idx_test_pre], self.labels_test)\n","        \n","\n","        if verbose:\n","            print('G+U+T:', round(train_acc_all,4), round(valid_acc_all,4), round(test_acc_all,4))\n","\n","\n","\n","        \n","        if (self.PRED_TYPE == 'net'):\n","            loss_train,loss_valid,loss_test,train_acc_sel, valid_acc_sel, test_acc_sel, preds_sel = (\n","                loss_train.item(),loss_valid.item(),loss_test.item(),\n","                train_acc_net, valid_acc_net, test_acc_net, preds.data.cpu().numpy())\n","        elif (self.PRED_TYPE == 'netshareu'):\n","            loss_train,loss_valid,loss_test,train_acc_sel, valid_acc_sel, test_acc_sel, preds_sel = (\n","                loss_train.item(),loss_valid.item(),loss_test.item(),\n","                train_acc_netshareu, valid_acc_netshareu, test_acc_netshareu, preds_netshareu.data.cpu().numpy())\n","        elif (self.PRED_TYPE == 'text'):\n","            loss_train,loss_valid,loss_test,train_acc_sel, valid_acc_sel, test_acc_sel, preds_sel = (\n","                loss_text_train.item(),loss_text_valid.item(),loss_text_test.item(),\n","                train_acc_text, valid_acc_text, test_acc_text, preds_text.data.cpu().numpy())\n","        elif (self.PRED_TYPE == 'all'):\n","            loss_train,loss_valid,loss_test,train_acc_sel, valid_acc_sel, test_acc_sel, preds_sel = (\n","                loss_all_train.item(),loss_all_valid.item(),loss_all_test.item(),\n","                train_acc_all, valid_acc_all, test_acc_all, preds_all.data.cpu().numpy())\n","        else:\n","            print('wrong PRED_TYPE')\n","            exit()\n","        \n","        result_table = [[train_acc_net, valid_acc_net, test_acc_net], \n","            [train_acc_shareu, valid_acc_shareu, test_acc_shareu], \n","            [train_acc_netshareu, valid_acc_netshareu, test_acc_netshareu], \n","            [train_acc_text, valid_acc_text, test_acc_text], \n","            [train_acc_nettext, valid_acc_nettext, test_acc_nettext], \n","            [train_acc_all, valid_acc_all, test_acc_all]]\n","        # return loss_list, train_acc_list, dev_acc_list, test_acc_list\n","        return (preds_all[self.idx_test_pre],self.labels_test,loss_train,loss_valid,loss_test,train_acc_sel,\n","                valid_acc_sel, test_acc_sel, preds_sel, result_table)\n"," \n","\n","        \n","    \n","    def run(self):\n","            \n","            # Train model\n","            best_yuce_tag,labels_test,loss_list, train_acc_list, dev_acc_list, test_acc_list = self._train()\n","        \n","            # Evaluate trained model\n","            self.model.load_state_dict(torch.load('/home/kayzhou/zhangyue/text/text_UNION/test_GCN_LSTM/saved_models/%s' % (self.MODEL_NAME)), strict=False)\n","            # (loss_train_val, loss_valid_val, loss_test_val, \n","            #     train_acc_sel, valid_acc_sel, test_acc_sel, preds_sel, result_table) = self._evaluate()\n","            # print(np.array(result_table)[:, 2])\n","\n","            if (self.SUPERVISE_FLAG == 'unsup1'):\n","                fout = open('temp/%s_unsup_pred.pickle' % self.DATASET, 'wb')\n","                preds_numpy = preds_sel\n","                print(preds_numpy.shape)\n","                pkl.dump(preds_numpy, fout)\n","                fout.close()\n","            \n","            return best_yuce_tag,labels_test,loss_list, train_acc_list, dev_acc_list, test_acc_list\n","\n","\n","if __name__ == '__main__':\n","    # Hyper Parameters\n","    ap = argparse.ArgumentParser()\n","    ap.add_argument(\"-d\", \"--dataset\", type=str, default=\"one_month_network_202010\",\n","                    help=\"Dataset string\")\n","    ap.add_argument(\"-e\", \"--epochs\", type=int, default=1000,\n","                    help=\"Number training epochs\")\n","    ap.add_argument(\"-hd\", \"--hidden\", type=int, default=16,\n","                    help=\"Number hidden units\")\n","    ap.add_argument(\"-b\", \"--bases\", type=int, default=-1,\n","                    help=\"Number of bases used (-1: all)\")\n","    ap.add_argument(\"-lr\", \"--learnrate\", type=float, default=0.001,\n","                    help=\"Learning rate\")\n","    ap.add_argument(\"-l2\", \"--l2norm\", type=float, default=5e-4,\n","                    help=\"L2 normalization of input weights\")\n","    ap.add_argument(\"-tm\", \"--text_model\", type=str, default=\"HLSTM\",\n","                    help=\"text model: select from 'SkipThought'/'HLSTM'\")\n","    ap.add_argument(\"-sf\", \"--supervise_flag\", type=str, default=\"supervise\",\n","                    help=\"supervise flag: select from 'supervise'/'unsup1'/'unsup2'\")\n","    ap.add_argument(\"-pt\", \"--pred_type\", type=str, default=\"all\",\n","                    help=\"prediction method: select from 'net'/'netshareu'/'text'/No doc'\")\n","    args = vars(ap.parse_args(args=[]))\n","    dataset = args['dataset']\n","\n","    \n","    np.random.seed(1)\n","    torch.manual_seed(1)\n","    torch.cuda.manual_seed(1)\n","    \n","\n","    trainer = Trainer(args)\n","    best_yuce_tag,labels_test,loss_list, train_acc_list, dev_acc_list, test_acc_list = trainer.run()  \n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPb2mCuk4keJk4hfUrbLpkC","collapsed_sections":[],"mount_file_id":"1AaRcSQ8tLgYnCiaiO-iuRSMh5MdiuXKk","name":"run.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.13 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"e8d40850c2a0f24b66f067e47dfa0a8004f5b10da74c53ddf9ba21a3b5b0a20a"}}},"nbformat":4,"nbformat_minor":0}
