{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":91960,"status":"ok","timestamp":1651717685169,"user":{"displayName":"张悦","userId":"05797549964769432427"},"user_tz":-480},"id":"4f9d9157"},"outputs":[],"source":["import numpy as np\n","def get_words_embeding(glove_file):\n","    words_embeding_dict = {}\n","    words_embeding_set = set()#别人训练的glove所包含的词集合\n","    for word_vector in open(glove_file,\"r\",encoding='utf-8').readlines():\n","        word_vector = word_vector.rstrip().split()\n","        #print(word_vector)\n","        word = word_vector[0]  #这个零 代表的是索引  下面的 一  也是同样的道理\n","        vector = np.asarray(word_vector[1:], \"float32\")\n","        words_embeding_dict[word] = vector\n","        words_embeding_set.add(word)\n","    return words_embeding_dict,words_embeding_set\n","#返回的一个为word和对应的嵌入的字典，另一个为glove别人训练的模型中包含的word\n","words_embeding_dict,words_embeding_set = get_words_embeding(r\"/home/kayzhou/zhangyue/text_ML/data/glove.twitter.27B.200d.txt\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":162026,"status":"ok","timestamp":1651717851713,"user":{"displayName":"张悦","userId":"05797549964769432427"},"user_tz":-480},"id":"4e7da742","outputId":"82cbc85e-fece-4f4e-f386-c63471244eb8"},"outputs":[{"name":"stderr","output_type":"stream","text":["3760566it [04:36, 13609.45it/s]\n","417841it [00:30, 13706.85it/s]\n"]}],"source":["from tqdm import tqdm\n","# classfied_hashtag_list = []\n","# for line in open(r\"E:\\hashtag标注\\top200.txt\",\"r\"):\n","#     classfied_hashtag = line.strip().split(\" \")[0]\n","#     classfied_hashtag_list.append(classfied_hashtag)\n","\n","tweet_embedding = []\n","tag_list = []\n","lujing = [r\"/home/kayzhou/zhangyue/text_ML/data/one_tweet_class_train.txt\",\n","         r\"/home/kayzhou/zhangyue/text_ML/data/one_tweet_class_dev.txt\"]\n","j=0\n","for i in lujing:\n","    for line in tqdm(open(i)):\n","        line = line.strip().split(\" \") \n","#         print(line)\n","        text = line[0:len(line)-1]\n","#         print(text)\n","        tag = line[-1]\n","\n","        one_tweet_embeding = np.array([0]*200,dtype=\"float64\")\n","\n","        embeding_tweet_len = 0\n","        j=j+1\n","        for word in text:\n","            if word in words_embeding_set: \n","                one_tweet_embeding += np.array(words_embeding_dict[word])  \n","                embeding_tweet_len += 1\n","        if embeding_tweet_len==0:\n","            one_tweet_final_embeding = one_tweet_embeding\n","        else:\n","            one_tweet_final_embeding = one_tweet_embeding/embeding_tweet_len\n","        tweet_embedding.append(one_tweet_final_embeding) \n","        tag_list.append(int(tag))"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":781,"status":"ok","timestamp":1651717852481,"user":{"displayName":"张悦","userId":"05797549964769432427"},"user_tz":-480},"id":"b732809f","outputId":"3841fb21-1812-4001-a380-9c484026163e"},"outputs":[{"name":"stderr","output_type":"stream","text":["4000it [00:00, 13924.12it/s]\n"]}],"source":["test_tweet_embedding = []\n","test_tag_list = []\n","\n","for line in tqdm(open(r\"/home/kayzhou/zhangyue/text_ML/data/one_tweet_class_test.txt\")):\n","    line = line.strip().split(\" \") \n","#         print(line)\n","    text = line[0:len(line)-1]\n","#         print(text)\n","    tag = line[-1]\n","\n","    one_tweet_embeding = np.array([0]*200,dtype=\"float64\")\n","\n","    embeding_tweet_len = 0\n","    for word in text:\n","        if word in words_embeding_set: \n","            one_tweet_embeding += np.array(words_embeding_dict[word])  \n","            embeding_tweet_len += 1\n","    if embeding_tweet_len==0:\n","        one_tweet_final_embeding = one_tweet_embeding\n","    else:\n","        one_tweet_final_embeding = one_tweet_embeding/embeding_tweet_len\n","    test_tweet_embedding.append(one_tweet_final_embeding) \n","    test_tag_list.append(int(tag))\n"]},{"cell_type":"markdown","metadata":{"id":"925290cd"},"source":["# 单条推文机器学习"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":745,"status":"ok","timestamp":1651717853217,"user":{"displayName":"张悦","userId":"05797549964769432427"},"user_tz":-480},"id":"ce437a27"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","import joblib\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import classification_report\n","from sklearn.svm import LinearSVC"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":353,"status":"ok","timestamp":1651717853564,"user":{"displayName":"张悦","userId":"05797549964769432427"},"user_tz":-480},"id":"fbd58213"},"outputs":[],"source":["# Multinomial Naive Bayes Classifier\n","def naive_bayes_classifier(train_x, train_y):\n","    #连续性数据\n","    from sklearn.naive_bayes import GaussianNB\n","    model = GaussianNB()\n","    model.fit(train_x, train_y)\n","    return model\n","\n","\n","# KNN Classifier\n","def knn_classifier(train_x, train_y):\n","    from sklearn.neighbors import KNeighborsClassifier\n","    model = KNeighborsClassifier()\n","    model.fit(train_x, train_y)\n","    return model\n","\n","\n","# Logistic Regression Classifier\n","def logistic_regression_classifier(train_x, train_y):\n","    from sklearn.linear_model import LogisticRegression\n","    model = LogisticRegression(penalty='l2')\n","    model.fit(train_x, train_y)\n","    return model\n","\n","\n","# Random Forest Classifier\n","def random_forest_classifier(train_x, train_y):\n","    from sklearn.ensemble import RandomForestClassifier\n","    model = RandomForestClassifier(n_estimators=8)\n","    model.fit(train_x, train_y)\n","    return model\n","\n","\n","# Decision Tree Classifier\n","def decision_tree_classifier(train_x, train_y):\n","    from sklearn import tree\n","    model = tree.DecisionTreeClassifier()\n","    model.fit(train_x, train_y)\n","    return model\n","\n","\n","# GBDT(Gradient Boosting Decision Tree) Classifier\n","def gradient_boosting_classifier(train_x, train_y):\n","    from sklearn.ensemble import GradientBoostingClassifier\n","    model = GradientBoostingClassifier(n_estimators=200)\n","    model.fit(train_x, train_y)\n","    return model\n","\n","\n","# SVM Classifier\n","def svm_classifier(train_x, train_y):\n","    from sklearn.svm import SVC\n","    model = SVC(kernel='rbf', probability=True)\n","    model.fit(train_x, train_y)\n","    return model\n","\n","\n","# SVM Linear Classifier\n","def svm_linear_classifier(train_x, train_y):\n","    model = LinearSVC()\n","    model.fit(train_x, train_y)\n","    return model\n","\n","\n","# SVM Classifier using cross validation\n","def svm_cross_validation(train_x, train_y):\n","    from sklearn.model_selection import GridSearchCV\n","    from sklearn.svm import SVC\n","    model = SVC(kernel='rbf', probability=True)\n","    #1e-3, 1e-2, 1e-1, 1, 10,\n","    param_grid = {'C': [100, 1000], 'gamma': [0.001, 0.0001]}\n","    grid_search = GridSearchCV(model, param_grid, n_jobs=1, verbose=1)\n","    grid_search.fit(train_x, train_y)\n","    best_parameters = grid_search.best_estimator_.get_params()\n","    for para, val in list(best_parameters.items()):\n","        print(para, val)\n","    model = SVC(kernel='rbf', C=best_parameters['C'],\n","                gamma=best_parameters['gamma'], probability=True)\n","    model.fit(train_x, train_y)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":408,"status":"ok","timestamp":1651718536734,"user":{"displayName":"张悦","userId":"05797549964769432427"},"user_tz":-480},"id":"cead4f34"},"outputs":[],"source":["def train():\n","    # read data\n","#     X, y = tweet_embeding, class_list\n","\n","#     print(\"Reading data finished! count:\", len(y))\n","\n","    # split train and test data\n","    X_train, X_test, y_train, y_test = tweet_embedding,test_tweet_embedding,tag_list,test_tag_list\n","\n","    print(\"Splitting data finished!\")\n","\n","#     # build one hot embedding\n","#     # v = DictVectorizer(dtype=np.int8, sparse=True, sort=False)\n","#     v = TfidfVectorizer(ngram_range=(1, 2), max_features=1000000)\n","#     X_train = v.fit_transform(X_train)\n","#     X_test = v.transform(X_test)\n","\n","#     # joblib.dump(v, f'data/{self.train_dir}/DictVectorizer.joblib')\n","#     joblib.dump(v, f'data/{self.train_dir}/TfidfVectorizer.joblib')\n","#     print(\"Building word embedding finished!\")\n","#     print(X_train[0].shape, X_train[1].shape)\n","#     print(X_train.shape, X_test.shape)\n","\n","    # X_train, y_train = SMOTE().fit_sample(X_train, y_train)\n","    # X_train, y_train = ADASYN().fit_sample(X_train, y_train)\n","    # X_train, y_train = RandomOverSampler(random_state=24).fit_sample(X_train, y_train)\n","    # X_train, y_train = RandomUnderSampler(random_state=42).fit_sample(X_train, y_train)\n","\n","    print(\"After sampling!\")\n","#     print(X_train.shape, X_test.shape)\n","\n","    # machine learning model\n","    \n","    #\"LR\",\"NB\",\"KNN\",\"RF\",\"DT\",\"GBDT\",\"SVM\" ,\"SVMCV\",\"SVC\"\n","    list_classifiers = ['LR','NB','DT','RF',\"GBDT\"]\n","    # list_classifiers = ['SVC']\n","    # list_classifiers = ['GBDT']\n","\n","    classifiers = {\n","            'NB': naive_bayes_classifier,            \n","            'KNN': knn_classifier,\n","            'LR': logistic_regression_classifier,\n","            'RF': random_forest_classifier,\n","            'DT': decision_tree_classifier,\n","            'SVM': svm_classifier,\n","            'SVMCV': svm_cross_validation,\n","            'GBDT': gradient_boosting_classifier,\n","            'SVC': svm_linear_classifier,\n","    }\n","\n","    for classifier in list_classifiers:\n","        print('******************* {} ********************'.format(classifier))\n","        if classifier == \"LR\":\n","            # clf = LogisticRegression(penalty='l2', multi_class=\"multinomial\", solver=\"sag\", max_iter=10e8)\n","            clf = LogisticRegression(penalty='l2', solver=\"sag\", max_iter=10e8, multi_class=\"auto\")\n","            clf.fit(X_train, y_train)\n","        elif classifier == \"GBDT\":\n","            clf = GradientBoostingClassifier(\n","                learning_rate=0.1, max_depth=3)\n","            clf.fit(X_train, y_train)\n","        else:\n","            clf = classifiers[classifier](X_train, y_train)\n","        print(\"fitting finished! Lets evaluate!\")\n","        evaluate(clf, X_train, y_train, X_test, y_test)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1651717853567,"user":{"displayName":"张悦","userId":"05797549964769432427"},"user_tz":-480},"id":"f1931a7e"},"outputs":[],"source":["def evaluate(clf, X_train, y_train, X_test, y_test):\n","    # CV\n","    # print('accuracy of CV=10:', cross_val_score(\n","    #     clf, X_train, y_train, cv=10).mean())\n","\n","    y_pred = clf.predict(X_test)\n","    print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"38374bb6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Splitting data finished!\n","After sampling!\n","******************* LR ********************\n","fitting finished! Lets evaluate!\n","              precision    recall  f1-score   support\n","\n","           0       0.59      0.85      0.70      2008\n","           1       0.73      0.41      0.52      1992\n","\n","    accuracy                           0.63      4000\n","   macro avg       0.66      0.63      0.61      4000\n","weighted avg       0.66      0.63      0.61      4000\n","\n","******************* NB ********************\n","fitting finished! Lets evaluate!\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.80      0.65      2008\n","           1       0.62      0.34      0.44      1992\n","\n","    accuracy                           0.57      4000\n","   macro avg       0.59      0.57      0.54      4000\n","weighted avg       0.58      0.57      0.54      4000\n","\n","******************* DT ********************\n","fitting finished! Lets evaluate!\n","              precision    recall  f1-score   support\n","\n","           0       0.58      0.64      0.61      2008\n","           1       0.59      0.52      0.56      1992\n","\n","    accuracy                           0.58      4000\n","   macro avg       0.58      0.58      0.58      4000\n","weighted avg       0.58      0.58      0.58      4000\n","\n","******************* RF ********************\n","fitting finished! Lets evaluate!\n","              precision    recall  f1-score   support\n","\n","           0       0.58      0.82      0.68      2008\n","           1       0.69      0.40      0.51      1992\n","\n","    accuracy                           0.61      4000\n","   macro avg       0.64      0.61      0.59      4000\n","weighted avg       0.63      0.61      0.59      4000\n","\n","******************* GBDT ********************\n","fitting finished! Lets evaluate!\n","              precision    recall  f1-score   support\n","\n","           0       0.58      0.87      0.69      2008\n","           1       0.73      0.35      0.48      1992\n","\n","    accuracy                           0.61      4000\n","   macro avg       0.65      0.61      0.59      4000\n","weighted avg       0.65      0.61      0.59      4000\n","\n"]}],"source":["train()"]}],"metadata":{"colab":{"name":"one_twitter_机器学习.ipynb","version":""},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"e8d40850c2a0f24b66f067e47dfa0a8004f5b10da74c53ddf9ba21a3b5b0a20a"}}},"nbformat":4,"nbformat_minor":5}
